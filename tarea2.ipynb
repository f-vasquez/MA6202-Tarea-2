{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pL1D_8eKVKwJ"
   },
   "source": [
    "# MA6202: Laboratorio de Ciencia de Datos\n",
    "\n",
    "**Profesor: Nicolás Caro**\\\n",
    "**Auxiliar: Rodrigo Lara M**\n",
    "\n",
    "**12/07/2020 - Tarea 2**\n",
    "\n",
    "\n",
    "**Integrantes del grupo**: Fabián Badilla M., Francisco Vásquez L., Javier Santibáñez M."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "id": "-SwppsHHVKwP"
   },
   "source": [
    "## Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "v8TbP36CVKwT"
   },
   "source": [
    "La siguiente evaluación corresponde a la segunda tarea del curso de laboratorio de ciencia de datos. A lo largo de la tarea se trabaja sobre un problema de clasificación binaria de imágenes torácicas de rayos X, buscando predecir si la imagen corresponde a neumonía.\n",
    "\n",
    "Se evaluará la presentación de sus resultados por medio de un informe, las condiciones de entrega requeridas son:\n",
    "* La extensión máxima del informe es de 8 planas a las que puede añadir 2 para anexos.\n",
    "* Debe adjuntar un repositorio ``git`` donde se incluya todo su código.\n",
    "    * A lo menos 1 ``commit`` por cada pregunta de la tarea\n",
    "    * Por lo menos 1 ``merge`` a través de su trabajo.\n",
    "* Incluya un documento ``jupyter notebook`` llamado ``tarea2.ipynb`` en el cual se exponga todo el procedimiento realizado.\n",
    "* Por  ́ultimo es necesario también entregar un archivo *hdf* denominado ``modelo.h5`` que contenga los pesos del mejor modelo de red neuronal obtenido.\n",
    "\n",
    "Tenga  en  mente  que  su  informe  será  revisado  por  un  equipo  técnico  que  debe  entender  a  cabalidad  su metodología, ser capaz de replicarlo y evaluarlo a partir de su lectura."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "id": "k7pUF047VKwX"
   },
   "source": [
    "## P1. Carga y transformación de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "l3xJ4jtjVKwa"
   },
   "source": [
    "Al abordar un problema de clasificación de imágenes con redes neuronales profundas, es importante optimizar el proceso de carga de datos. Al tratarse de imágenes, es de esperar que no todas las muestras puedan ser almacenadas en memoria de manera simultanea, por lo que es necesario construir un *generador*. El objetivo de la sección es construir un *generador* de muestras eficiente, que minimice el tiempo de carga de datos y optimice el uso de memoria.\n",
    "\n",
    "El conjunto de datos a utilizar está disponible en este [link](https://data.mendeley.com/datasets/rscbjbr9sj/2/files/f12eaf6d-6023-432f-acc9-80c9d7393433/ChestXRay2017.zip). En la Figura 1 se observan algunas muestras de cada clase. La carpeta ``train`` consta de alrededor de $5.000$ imágenes y la carpeta ``test``, cerca de $600$. Al ser un conjunto de datos pequeño, se emplean técnicas de aumentación de datos que serán detalladas a continuación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "dfQuN4W5VKwd"
   },
   "source": [
    "1. Instancie objetos de la clase ``torchvision.datasets.DataFolder`` que le permitan cargar las imágenes de las carpetas ``train`` y ``test``. Además, Construya la función ``loader``, que permite cargar muestras de la base de datos. Note que existen imágenes que tienen 1 sólo canal, estas deben ser transformadas a 3 canales mediante concatenación. Dicho procedimiento debe ocurrir en la función ``loader``.\n",
    "En el parámetro ``transform``, instancie un objeto de la clase ``torchvision.transforms.Compose`` que componga las siguientes transformaciones:\n",
    "\n",
    "* Escalamiento de la imagen a un tamaño de $224\\times 224$ pixeles. Además escale los valores de brillo delos pixeles a valores entre $0$ y $1$, dividiendo por el valor máximo del tipo de dato ``uint8``\n",
    "* Con probabilidad $\\frac{1}{2}$, voltee la imagen en el eje horizontal.\n",
    "* Rote la imagen, con respecto a su centro, con un ángulo aleatorio entre -$20°$ y $20°$.\n",
    "* Multiplique los valores de brillo de cada canal por un número aleatorio entre $1,2$ y $1,5$. Cada pixel debeser multiplicado por un número potencialmente distinto, es decir, a cada valor de brillo corresponde un número aleatorio potencialmente diferente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "wOmxicb9R7qc",
    "outputId": "8cc2a970-b76b-497d-a8f4-9b92ffffcb8a"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.manual_seed(1919)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W0C_HrGaVKwg",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.datasets import DatasetFolder\n",
    "from torchvision import transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DEAtA41DVKxA"
   },
   "outputs": [],
   "source": [
    "def loader(input):\n",
    "    '''Funcion que carga la imagen, si es de 1 canal la pasa a 3 canales '''\n",
    "    image = Image.open(input)\n",
    "    img = image.split()\n",
    "    if len(img) == 1:\n",
    "        return Image.merge('RGB', (img[0], img[0], img[0]))\n",
    "    else:\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "colab_type": "code",
    "id": "rYExsbdDVKxR",
    "outputId": "6a140d45-03e7-4310-be8b-11563e2e6820",
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''Ejemplo de carga de imagenes '''\n",
    "img = loader('data\\\\chest_xray\\\\train\\\\PNEUMONIA\\\\person1_bacteria_1.jpeg')\n",
    "# print(img.size)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wBRsil16VKxh"
   },
   "outputs": [],
   "source": [
    "'''Transformaciones necesarias '''\n",
    "\n",
    "def ajust_brillo(img):\n",
    "    '''Multiplica los valores de cada pixel por un número aleatorio entre 1.2 y 1.5 '''\n",
    "    return img.point(lambda i: i*np.random.uniform(1.2,1.5))\n",
    "\n",
    "transf = transforms.Compose([transforms.Resize([224, 224]),\n",
    "                             transforms.ColorJitter(brightness=(0,1)),\n",
    "                             transforms.RandomHorizontalFlip(p=0.5),\n",
    "                             transforms.RandomRotation(degrees=(-20,20)),\n",
    "                             transforms.Lambda(lambda x: ajust_brillo(x)),\n",
    "                             transforms.ToTensor()\n",
    "                            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "76Qrr2naVKxz"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Data debe estar en carpeta: data/chest_xray\n",
    "Lo deje en gitignore porque pesa mucho y puede morir github\n",
    "'''\n",
    "data_train = DatasetFolder('data/chest_xray/train', loader = loader, extensions=('jpeg'), transform=transf)\n",
    "data_test = DatasetFolder('data/chest_xray/test', loader = loader, extensions=('jpeg'), transform=transf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "QNnLduSjVKyH",
    "outputId": "1bbeb4a1-1688-441a-db88-f1da20138be9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "''' Otro ejemplo '''\n",
    "plt.imshow(data_train[0][0].permute(1, 2, 0), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7fnhTrRYR7r2"
   },
   "outputs": [],
   "source": [
    "def muestreo_plot_imagenes(n=5):\n",
    "    ''' Plotea n imagenes aleatorias del DatasetFolder train '''\n",
    "    fig, ax = plt.subplots(1,n,figsize=(15,8))\n",
    "    for k in range(n):\n",
    "        index = np.random.randint(len(data_train))\n",
    "        ax[k].imshow(data_train[index][0].permute(1, 2, 0),cmap=\"gray\")\n",
    "        if data_train[index][1] == 0:\n",
    "            ax[k].title.set_text('Normal')\n",
    "        else:\n",
    "            ax[k].title.set_text('Pneumonia')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "colab_type": "code",
    "id": "me4wpFgoR7r_",
    "outputId": "ccd00a6a-1165-440a-fb14-0057d2f1ae3b"
   },
   "outputs": [],
   "source": [
    "muestreo_plot_imagenes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "CaAAQ6eCVKy0"
   },
   "source": [
    "Mediante perfilamiento de tiempo de cómputo seleccione las herramientas que le parezcan óptimas para implementar las transformaciones anteriores. Puede utilizar las librerías ``pytorch``, ``PIL``, ``skimage`` u ``opencv``. Incluya en el reporte, una comparación con herramientas de 2 procesamientos de su elección.\n",
    "\n",
    "**Observación:**  Se  recomienda  realizar  por  completo  las  secciones **P1** y **P2** antes de fundamentar su selección."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nlEJ1oKQVKy5"
   },
   "outputs": [],
   "source": [
    "'''Ahora con skimage '''\n",
    "import skimage\n",
    "from skimage import io\n",
    "\n",
    "def loader_sk(input):\n",
    "    '''Funcion que carga la imagen, si es de 1 canal la pasa a 3 canales, usando skimage '''\n",
    "    img = io.imread(input)\n",
    "    if len(img.shape) != 3:\n",
    "        return skimage.color.gray2rgb(img)\n",
    "    else:\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "colab_type": "code",
    "id": "TQ_mUhoDVKzk",
    "outputId": "93ce1ec8-98f5-4757-aa12-dd400973620f"
   },
   "outputs": [],
   "source": [
    "'''Ejemplo de carga de imagenes con skimage '''\n",
    "img_sk = loader_sk('data\\\\chest_xray\\\\train\\\\PNEUMONIA\\\\person1_bacteria_1.jpeg')\n",
    "# print(img_sk.shape)\n",
    "# print(type(img_sk))\n",
    "plt.imshow(img_sk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D1SF6p-MVKz8"
   },
   "outputs": [],
   "source": [
    "'''Transformaciones necesarias, usando skimage '''\n",
    "import skimage.transform as transform_sk\n",
    "from skimage.exposure import adjust_gamma\n",
    "\n",
    "def volteo_horizontal_random(image):\n",
    "    '''Con probabilidad  1/2, voltea la imagen en el eje horizontal '''\n",
    "    if np.random.choice([True,False], p = [0.5,0.5]):\n",
    "        return np.fliplr(image)\n",
    "    else:\n",
    "        return image\n",
    "\n",
    "def ajustar_brillo_random(image):\n",
    "    ''' Multiplica los valores de cada pixel por un número aleatorio entre 1.2 y 1.5 '''\n",
    "    for fila in range(image.shape[0]):\n",
    "        for col in range(image.shape[1]):\n",
    "                for canal in range(image.shape[2]):\n",
    "                    temporal = image[fila,col,canal]*np.random.uniform(1.2,1.5)\n",
    "                    if temporal > 1.0 :\n",
    "                      image[fila,col,canal] = 1\n",
    "                    else:\n",
    "                      image[fila,col,canal] = temporal\n",
    "    return image\n",
    "\n",
    "transf_sk = transforms.Compose([transforms.Lambda(lambda x: transform_sk.resize(x,output_shape=(224,224))),\n",
    "                                transforms.Lambda(lambda x: adjust_gamma(x,gamma=1/np.max(x))),\n",
    "                                transforms.Lambda(lambda x: volteo_horizontal_random(x)),\n",
    "                                transforms.Lambda(lambda x: transform_sk.rotate(x,np.random.uniform(-20,20))),\n",
    "                                transforms.Lambda(lambda x: ajustar_brillo_random(x)),\n",
    "                                transforms.ToTensor()\n",
    "                                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ExKqfk3BVK0O"
   },
   "outputs": [],
   "source": [
    "data_train_sk = DatasetFolder('data/chest_xray/train', loader = loader_sk, \n",
    "                              extensions=('jpeg'), transform=transf_sk)\n",
    "data_test_sk = DatasetFolder('data/chest_xray/test', loader = loader_sk, \n",
    "                             extensions=('jpeg'), transform=transf_sk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "K4c9HzsrVK0h",
    "outputId": "c5b3fb8a-e213-4eec-e6b2-a06f6aa1811e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "''' Otro ejemplo, skimage '''\n",
    "plt.imshow(data_train_sk[0][0].permute(1, 2, 0), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "mLGiKXAHVK01",
    "outputId": "ada83c1c-48d5-4260-b38d-04596e3f7d0e"
   },
   "outputs": [],
   "source": [
    "''' Perfilamiento con transformaciones pytorch, loader PIL '''\n",
    "%timeit -r 10 data_train[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "fI33EakpVK1B",
    "outputId": "99bd6371-5c41-46e0-bdaf-0752eae097fe"
   },
   "outputs": [],
   "source": [
    "''' Perfilamiento con transformaciones skimage, loader skimage '''\n",
    "%timeit -r 10 data_train_sk[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "6l78NeDAVK1P"
   },
   "source": [
    "2. Visualice la cantidad de muestras de cada clase en las carpetas ``train`` y ``test``. Discuta sobre las implicancias de estas distribuciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "olZ7mo6eVK1R",
    "outputId": "1c61b309-a03a-4ddf-8606-50d13381c5f3"
   },
   "outputs": [],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WcWGuOCaVK1h"
   },
   "outputs": [],
   "source": [
    "def suma_clases(data):\n",
    "    '''Dado un DatasetFolder, retorna cantidad de datos en clase 0 y 1 '''\n",
    "    suma_c1 = sum(data.targets)\n",
    "    suma_c0 = len(data.targets)-suma_c1\n",
    "    return suma_c0, suma_c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "colab_type": "code",
    "id": "qMAOj4YHVK1u",
    "outputId": "f6641488-6b91-4751-fd87-cc5d51fffaa1"
   },
   "outputs": [],
   "source": [
    "c0_train, c1_train = suma_clases(data_train)\n",
    "c0_test, c1_test = suma_clases(data_test)\n",
    "\n",
    "clases = pd.DataFrame([[c0_train,c0_test], [c1_train,c1_test], \n",
    "                       [c0_train+c1_train,c0_test+c1_test]], \n",
    "                      columns=['Train','Test'],\n",
    "                      index=['Normal (Clase 0)', 'Pneumonia (Clase 1)','Total'])\n",
    "# print(clases.to_latex())\n",
    "clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "colab_type": "code",
    "id": "o7o-hNUEVK2R",
    "outputId": "21787dc0-4970-406a-a3d3-8dc8a6bd97e0",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''Bar plot distribucion conjunto train y test '''\n",
    "ax = clases[:2].T.plot.bar(rot=0,grid=True, figsize=(10,7), fontsize=13)\n",
    "for p in ax.patches:\n",
    "    ax.annotate(p.get_height(), (p.get_x()* 1.005+p.get_width()/2., p.get_height()*1.005),\n",
    "                ha='center',fontsize=13)\n",
    "plt.title('Distribución conjunto train y test',fontsize=15)\n",
    "plt.legend(fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "ohXxRSwzVK2g"
   },
   "source": [
    "Debido a que el balance de clases es diferente entre la carpeta ``train`` de la carpeta ``test``, es necesario definir cual es la distribución de clases del *problema*. En lo que sigue, asumiremos que dicha distribución es la que presenta la carpeta ``test``. Esto quiere decir que en un entorno de producción, se espera recibir muestras distribuidas de manera similar a tal conjunto, que llamaremos *conjunto de prueba*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "_RDRzm3fVK2i"
   },
   "source": [
    "3. Separe los índices del objeto ``DataFolder`` de la carpeta ``train`` en un *conjunto de entrenamiento* y un *conjunto de validación*, con un $80$ y $20\\%$ de las muestras respectivamente. Construya la clase ``ReplicarMuestreoDePrueba`` que herede de ``torch.utils.data.Sampler`` y permita iterar sobre el conjunto de validación de tal forma que replique la distribución de clases del *conjunto de prueba*, mediante un sobremuestreo de la clase minoritaria. Esta clase debe poseer los métodos:\n",
    "    * ``__init__(self, etiquetas_prueba, indices_val, etiquetas_val):`` que guarde como atributos las variables necesarias para generar el muestreo deseado.\n",
    "    * ``__iter__(self):`` que entregue un ``iterator`` sobre los índices del muestreo deseado\n",
    "    \n",
    "*Hint:* Puede ser útil emplear ``numpy.random.choice``. Observe que tendrá índices de validación duplicados.\n",
    "\n",
    "**Observación:** Asuma que se trata de un problema de clasificación binaria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "znzRGvZER7t4"
   },
   "outputs": [],
   "source": [
    "'''Separacion indices en train-validacion '''\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "index_train, index_val = train_test_split(np.arange(len(data_train)), \n",
    "                                          test_size = .2, random_state=1919)\n",
    "'''Etiquetas de validacion '''\n",
    "y_val = np.array([data_train[x][1] for x in index_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N5O2weltVK20",
    "outputId": "ad40dd9a-0275-4d61-aa7b-7a76aa9e64a8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Tamaño conjunto de entrenamiento: ', len(index_train))\n",
    "print('Tamaño conjunto de validacion: ', len(index_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-EHuRhNhVK3C"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Sampler\n",
    "\n",
    "class ReplicarMuestreoDePrueba(Sampler):\n",
    "    '''\n",
    "    Permite iterar sobre el conjunto de validación tal que replica la distribución\n",
    "    de clases del conjunto de prueba, mediante un sobremuestreo de la clase minoritaria \n",
    "    '''\n",
    "    def __init__(self, etiquetas_prueba, indices_val, etiquetas_val):\n",
    "        self.etiquetas_prueba = etiquetas_prueba\n",
    "        self.indices_val = indices_val\n",
    "        self.etiquetas_val = etiquetas_val\n",
    "\n",
    "    def __iter__(self):\n",
    "        p_test = np.sum(self.etiquetas_prueba)/len(self.etiquetas_prueba) # prob de ser 1, en testeo\n",
    "        if p_test < 0.5:\n",
    "            p_vect = self.etiquetas_val\n",
    "        else:\n",
    "            p_vect = 1 - self.etiquetas_val\n",
    "        p_vect = p_vect/np.sum(p_vect) # debe sumar 1\n",
    "        sampleo = self.indices_val\n",
    "        sampleo_eti = self.etiquetas_val\n",
    "        p_sampleo = np.sum(sampleo_eti)/len(sampleo_eti)\n",
    "        num_iter = 1e4\n",
    "        i=0\n",
    "        while abs(p_sampleo - p_test) > 1e-3 and i < num_iter:\n",
    "            index = np.random.choice(np.arange(len(self.indices_val)), size=1, p=p_vect)\n",
    "            sampleo = np.append(sampleo, self.indices_val[index])\n",
    "            sampleo_eti = np.append(sampleo_eti, self.etiquetas_val[index])\n",
    "            p_sampleo = np.sum(sampleo_eti)/len(sampleo_eti)\n",
    "            i+=1\n",
    "        return iter(sampleo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "5w92IH__R7uN",
    "outputId": "6704463c-386a-4430-86f9-b56b8866501c"
   },
   "outputs": [],
   "source": [
    "'''Distribucion conjunto de test '''\n",
    "y_test = np.array([obs[1] for obs in data_test])\n",
    "np.sum(y_test)/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "q0Cnm9mWVK3d",
    "outputId": "54a9e519-bbb0-4ce9-c325-377a6c08beef",
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''Se comprueba que samplea distribucion similar a la de test '''\n",
    "Sampleo = ReplicarMuestreoDePrueba(y_test, index_val, y_val)\n",
    "el_iter = Sampleo.__iter__()\n",
    "prueba = [y_val[list(index_val).index(x)] for x in el_iter]\n",
    "\n",
    "print('Distribucion previa: ', np.sum(y_val)/len(y_val))\n",
    "print('Cantidad nuevos agregados: ', len(prueba)-len(y_val))\n",
    "print('Distribucion nueva: ', np.sum(prueba)/len(prueba)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "1-qcOprDVK3p"
   },
   "source": [
    "4. Instancie objetos de la clase ``torch.utils.data.DataLoader`` para recorrer sus conjuntos de entrenamiento, validación y prueba. Para ello utilice los objetos adecuados en el parámetro ``sampler``. Discuta en el reporte las implicancias en tiempos de cómputo del parámetro ``num_workers``\n",
    "\n",
    "*Hint:* Puede ser útil usar la clase ``torch.utils.data.sampler.SubsetRandomSampler`` para el *conjunto de entrenamiento* y ``torch.utils.data.RandomSampler`` para el *conjunto de prueba*.\n",
    "\n",
    "**Observación:** Se recomienda realizar por completo las secciones **P1** y **P2** para fundamentar su discusión. Además, como referencia, en ``Colaboratory`` el parámetro ``batch_size=16`` es compatible con los recursos de la plataforma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z8Y41VWQVK3-"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "train_DL = DataLoader(data_train, batch_size=16,\n",
    "                      sampler = SubsetRandomSampler(index_train))\n",
    "valid_DL = DataLoader(data_train, batch_size=16,\n",
    "                      sampler = ReplicarMuestreoDePrueba(y_test, index_val, y_val))\n",
    "test_DL = DataLoader(data_test, batch_size=16,\n",
    "                     sampler = RandomSampler(data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t3Rnhw64R7uo"
   },
   "outputs": [],
   "source": [
    "'''Comparacion tiempos de cómputo del parámetro num_workers '''\n",
    "def DL_num_workers(n=0):\n",
    "    '''Recorre DataLoader del conjunto de train, usando n num_workers '''\n",
    "    train_DL = DataLoader(data_train, batch_size=16, num_workers = n,\n",
    "                      sampler = SubsetRandomSampler(index_train))\n",
    "    i = 0\n",
    "    for x in train_DL:\n",
    "        if i > 1:\n",
    "            break\n",
    "        i +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "iMPV4etwR7ut",
    "outputId": "ce3c201c-7b97-4397-be89-a41984070a9a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%timeit DL_num_workers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "VFrySjizR7u2",
    "outputId": "9aa650c6-fd97-4c1d-937a-7d7356b1f2a1",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%timeit DL_num_workers(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "J0nYgOk3R7vB",
    "outputId": "4336188f-71c0-4fc1-8395-51c5ba5cb586"
   },
   "outputs": [],
   "source": [
    "%timeit DL_num_workers(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "tNw_9eshYo5n",
    "outputId": "dd9c6310-ad81-4452-b265-90d3df1545c4"
   },
   "outputs": [],
   "source": [
    "%timeit DL_num_workers(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "m_rykwALY4XX",
    "outputId": "796257ad-c3ab-49ef-bcd4-c75618974edd"
   },
   "outputs": [],
   "source": [
    "%timeit DL_num_workers(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "id": "LZ_Lx5D3VK4o"
   },
   "source": [
    "## P2. Redes convolucionales profundas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "MFmmRzyGVK4v"
   },
   "source": [
    "El objetivo de esta sección es construir una red neuronal profunda para el problema de clasificación de imágenes de rayos X sobre neumonía. Dicha red debe ser implementada en ``Pytorch``.\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1400/1*yG6z6ESzsRW-9q5F_neOsg.png\" alt=\"drawing\" style=\"width:600px;\" title=\"(a) Capa de convolución depthwise\"/>\n",
    "<img src=\"https://miro.medium.com/max/1400/1*Q7a20gyuunpJzXGnWayUDQ.png\" alt=\"drawing\" style=\"width:600px;\" title=\"(b) Capa de convolución pointwise\"/>\n",
    "\n",
    "<center>Figura 2: Componentes de la capa de convolución <em>Depthwise Separable Convolution</em></center>\n",
    "\n",
    "\n",
    "Se implementa un tipo de capa de convolución conocida como *Dephtwise Separable Convolution*. Esta consiste en separar una capa de $k$ filtros de convolución de tamaño $n\\times n$, i.e. definida por $k$ filtros de tamaño $n\\times n\\times c$ (donde $c$ representa el número de canales) en dos capas de convolución:\n",
    "\n",
    "* Una capa de convolución llamada *Depthwise*, definida por $c$ filtros de tamaño $n\\times n\\times 1$, donde cada canal de entrada es convolucionado con su respectivo filtro, obteniéndose así un volumen de salida de $c$ canales. En la figura 2a se ilustra lo mencionado para $n= 5$, $c= 3$ y un $stride= 1$.\n",
    "\n",
    "\n",
    "* Una capa de convolución llamada *pointwise*, definida por $k$ filtros de tamaño $1\\times 1\\times c$ que se aplica al volumen de salida de la capa *depthwise*. En la figura 2b se muestra su funcionamiento para $c= 3$ y $k= 256$. Cabe notar que la función de activación se aplica sólo en el volumen de salida de esta capa.\n",
    "\n",
    "\n",
    "1. Construya la clase de ``DWSepConv2d`` que herede de ``torch.nn`` y haga overriding de los métodos ``__init__`` y ``forward``.  El  primero  debe  recibir  como  parámetros: ``in_channels``, ``out_channels``, ``kernel_size``, ``padding``, ``bias=True``. Estos tienen el significado usual empleados en los módulos ``torch.nn``.\n",
    "\n",
    "*Hint:* Observe que para el ejemplo de la Figura 2 los parámetros tomarían los valores ``in_channels=3``, ``out_channels=256`` y ``kernel_size=5``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T20:19:53.771216Z",
     "start_time": "2020-07-16T20:19:53.376272Z"
    },
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "RzGdrqF1yxvU"
   },
   "outputs": [],
   "source": [
    "# Imports:\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T20:19:53.807120Z",
     "start_time": "2020-07-16T20:19:53.801136Z"
    },
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "1Omsczi1m3oM"
   },
   "outputs": [],
   "source": [
    "class DWSepConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, padding, bias=True):\n",
    "        super().__init__()\n",
    "        self.depthwise = nn.Conv2d(in_channels, in_channels, kernel_size=kernel_size, \n",
    "                                   stride=1,groups=in_channels, padding=padding, bias=bias)\n",
    "        self.pointwise = nn.Conv2d(in_channels, out_channels, kernel_size=1,\n",
    "                                   stride=1, bias=bias)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.depthwise(x.float())\n",
    "        x = F.relu(self.pointwise(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "7krE9kwbVK5H"
   },
   "source": [
    "2. Construya una red convolucional profunda mediante la clase ``VGG16DWSep`` que hereda ``torch.nn`` y hace overriding de los métodos ``__init__`` y ``forward``, de tal manera que la red posea la estructura detallada en la Tabla 1.  \n",
    "  \n",
    "  Obtenga el número de parámetros que tiene esta estructura y el número de parámetros que habrían sido utilizados si todas las capas ``DWSepConv2d`` hubiesen sido ``Conv2d``. Discuta la ganancia en tiempo de cómputo en entrenamiento y prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "KJkrzLXfyxvq"
   },
   "source": [
    "|     capa    | tamaño filtro | padding | stride | # filtros |\n",
    "|:-----------:|:-------------:|:-------:|:------:|:---------:|\n",
    "|    Conv2d   |       3       |    1    |    1   |     64    |\n",
    "|    Conv2d   |       3       |    1    |    1   |     64    |\n",
    "|  MaxPool2d  |       2       |    0    |    2   |     -     |\n",
    "| DWSepConv2d |       3       |    1    |    1   |    128    |\n",
    "| DWSepConv2d |       3       |    1    |    1   |    128    |\n",
    "|  MaxPool2d  |       2       |    0    |    2   |     -     |\n",
    "| DWSepConv2d |       3       |    1    |    1   |    256    |\n",
    "| BatchNorm2d |       -       |    -    |    -   |     -     |\n",
    "| DWSepConv2d |       3       |    1    |    1   |    256    |\n",
    "| BatchNorm2d |       -       |    -    |    -   |     -     |\n",
    "| DWSepConv2d |       3       |    1    |    1   |    256    |\n",
    "|  MaxPool2d  |       2       |    0    |    2   |     -     |\n",
    "| DWSepConv2d |       3       |    1    |    1   |    512    |\n",
    "| BatchNorm2d |       -       |    -    |    -   |     -     |\n",
    "| DWSepConv2d |       3       |    1    |    1   |    512    |\n",
    "| BatchNorm2d |       -       |    -    |    -   |     -     |\n",
    "| DWSepConv2d |       3       |    1    |    1   |    512    |\n",
    "|  MaxPool2d  |       2       |    0    |    2   |     -     |\n",
    "|   Flatten   |       -       |    -    |    -   |     -     |\n",
    "|    Linear   |       -       |    -    |    -   |    1024   |\n",
    "| Dropout(.7) |       -       |    -    |    -   |     -     |\n",
    "|    Linear   |       -       |    -    |    -   |    512    |\n",
    "| Dropout(.5) |       -       |    -    |    -   |     -     |\n",
    "|    Linear   |       -       |    -    |    -   |     2     |\n",
    "\n",
    "  \n",
    "  <center>Tabla 1: Estructura de la red VGG16DWSep</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T20:19:58.931173Z",
     "start_time": "2020-07-16T20:19:58.915216Z"
    },
    "code_folding": [
     3,
     31
    ],
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "U3nuijrCyxvc"
   },
   "outputs": [],
   "source": [
    "class VGG16DWSep(nn.Module):\n",
    "    \"\"\"Red neuronal profunda VGG16 con separación Depthwise \n",
    "    descrita en la tabla 1 del enunciado\"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"Se hereda init y se definen todas las capas que participaran\"\"\" \n",
    "        super().__init__()\n",
    "        self.dw1 = DWSepConv2d(64, 128, 3, 1)\n",
    "        self.dw2 = DWSepConv2d(128,128, 3, 1)\n",
    "        self.dw3 = DWSepConv2d(128,256, 3, 1)\n",
    "        self.dw4 = DWSepConv2d(256,256, 3, 1)\n",
    "        self.dw5 = DWSepConv2d(256,256, 3, 1)\n",
    "        self.dw6 = DWSepConv2d(256,512, 3, 1)\n",
    "        self.dw7 = DWSepConv2d(512,512, 3, 1)\n",
    "        self.dw8 = DWSepConv2d(512,512, 3, 1)\n",
    "        self.conv1 = nn.Conv2d(3, 64, 3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64,64, 3, stride=1, padding=1)\n",
    "        self.max1 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.max2 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.max3 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.max4 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.bat1= nn.BatchNorm2d(256)\n",
    "        self.bat2= nn.BatchNorm2d(256)\n",
    "        self.bat3= nn.BatchNorm2d(512)\n",
    "        self.bat4= nn.BatchNorm2d(512)\n",
    "        self.lin1= nn.Linear(100352, 1024)\n",
    "        self.lin2= nn.Linear(1024,512)\n",
    "        self.lin3= nn.Linear(512,2)\n",
    "        self.drop1=nn.Dropout(p=0.7)\n",
    "        self.drop2=nn.Dropout(p=0.5)\n",
    "        self.flat= nn.Flatten()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"Se define el proceso en el orden que indica la tabla, usando la\n",
    "        funcion de activacion ReLU donde corresponda\"\"\"\n",
    "        x = x.view(-1,3,224,224)\n",
    "        x = F.relu(self.conv1(x.float()))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.max1(x)\n",
    "        x = self.dw1(x)\n",
    "        x = self.dw2(x)\n",
    "        x = self.max2(x)\n",
    "        x = self.dw3(x)\n",
    "        x = F.relu(self.bat1(x))\n",
    "        x = self.dw4(x)\n",
    "        x = F.relu(self.bat2(x))\n",
    "        x = self.dw5(x)\n",
    "        x = self.max3(x)\n",
    "        x = self.dw6(x)\n",
    "        x = F.relu(self.bat3(x))\n",
    "        x = self.dw7(x)\n",
    "        x = F.relu(self.bat4(x))\n",
    "        x = self.dw8(x)\n",
    "        x = self.max4(x)\n",
    "        x = self.flat(x)\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = self.drop1(x)\n",
    "        x = F.relu(self.lin2(x))\n",
    "        x = self.drop2(x)\n",
    "        x = F.relu(self.lin3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T20:13:52.470309Z",
     "start_time": "2020-07-16T20:13:52.456347Z"
    },
    "code_folding": [
     3,
     23
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Modo simio\n",
    "class VGG16_Conv(nn.Module):\n",
    "    \"\"\"Red equivalente a la anterior pero sin separacion depthwise\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64,64, kernel_size=3, stride=1, padding=1)\n",
    "        self.max = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.dw1 = nn.Conv2d(64, 128, 3, 1, 1)\n",
    "        self.dw2 = nn.Conv2d(128,128, 3, 1, 1)\n",
    "        self.dw3 = nn.Conv2d(128,256, 3, 1, 1)\n",
    "        self.bat1= nn.BatchNorm2d(256)\n",
    "        self.bat2= nn.BatchNorm2d(512)\n",
    "        self.dw4 = nn.Conv2d(256,256, 3, 1, 1)\n",
    "        self.dw5 = nn.Conv2d(256,512, 3, 1, 1)\n",
    "        self.dw6 = nn.Conv2d(512,512, 3, 1, 1)\n",
    "        self.flat= nn.Flatten()\n",
    "        self.lin1= nn.Linear(14*14*512, 1024)\n",
    "        self.drop1=nn.Dropout(p=0.7)\n",
    "        self.lin2= nn.Linear(1024,512)\n",
    "        self.drop2=nn.Dropout(p=0.5)\n",
    "        self.lin3= nn.Linear(512,2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1,3,224,224)\n",
    "        x = F.relu(self.conv1(x.float()))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.max(x)\n",
    "        x = F.relu(self.dw1(x))\n",
    "        x = F.relu(self.dw2(x))\n",
    "        x = self.max(x)\n",
    "        x = F.relu(self.dw3(x))\n",
    "        x = F.relu(self.bat1(x))\n",
    "        x = F.relu(self.dw4(x))\n",
    "        x = F.relu(self.bat1(x))\n",
    "        x = F.relu(self.dw4(x))\n",
    "        x = self.max(x)\n",
    "        x = F.relu(self.dw5(x))\n",
    "        x = F.relu(self.bat2(x))\n",
    "        x = F.relu(self.dw6(x))\n",
    "        x = F.relu(self.bat2(x))\n",
    "        x = F.relu(self.dw6(x))\n",
    "        x = self.max(x)\n",
    "        x = self.flat(x)\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = self.drop1(x)\n",
    "        x = F.relu(self.lin2(x))\n",
    "        x = self.drop2(x)\n",
    "        x = F.relu(self.lin3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T03:34:54.116583Z",
     "start_time": "2020-07-16T03:34:51.549361Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Se instancia un objeto de la clase VGG16 sin separación y a travez de\n",
    "summary, se observa cuantos parametros entrena\"\"\"\n",
    "mdl = VGG16_Conv()\n",
    "summary(mdl.cuda(), (3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T03:34:54.796616Z",
     "start_time": "2020-07-16T03:34:54.146504Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 937
    },
    "colab_type": "code",
    "hidden": true,
    "id": "zAnApKVFm3oX",
    "outputId": "2bc69a8e-4d88-4e19-9590-9e33b8de2a05"
   },
   "outputs": [],
   "source": [
    "\"\"\"Se instancia un objeto de la clase VGG16DWSep y se vuelve a observar\n",
    "la cantidad de parametros\"\"\"\n",
    "mdl = VGG16DWSep()\n",
    "summary(mdl.cuda(), (3,224,224))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "PjDEfYdCVK5Z"
   },
   "source": [
    "3. Transfiera los pesos de las dos primeras capas de convolución de la red ``VGG16`` preentrenada en *imageNet* a las dos primeras capas de la red ``VGG16DWSep`` construida y manténgalos constantes durante el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T03:34:55.916211Z",
     "start_time": "2020-07-16T03:34:54.826559Z"
    },
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "vAgMC3cGyxvk"
   },
   "outputs": [],
   "source": [
    "\"\"\" Se carga el modelo pre-entrenado: \"\"\"\n",
    "vgg16 = models.vgg16(pretrained=True)\n",
    "\n",
    "\"\"\"Se transfieren los pesos:\"\"\"\n",
    "mdl.conv1.weight.data = vgg16.features[0].weight.clone()\n",
    "mdl.conv2.weight.data = vgg16.features[2].weight.clone()\n",
    "\n",
    "\"\"\" Se mantienen constantes: \"\"\"\n",
    "for i, param in enumerate(mdl.parameters()):\n",
    "    if i in [0,2]:\n",
    "        param.requires_grad=False\n",
    "    if i>3:\n",
    "        break\n",
    "\n",
    "\"\"\"Se borra el modelo pre-entrenado para ahorrar memoria\"\"\"\n",
    "del(vgg16)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "oUR-fgmMVK5x"
   },
   "source": [
    "Al entrenar redes neuronales profundas, es usual emplear una heurística de regularización llamada *Early Stopping* que consiste en monitorear alguna métrica de desempeño (usualmente la función de costo) en un conjunto de validación, para así detener el entrenamiento cuando dicha métrica empeora de forma sostenida.\n",
    "\n",
    "En el siguiente fragmento de código ilustramos el uso de la heurística implementada en la clase ``EarlyStopping``:\n",
    "```c\n",
    "es = EarlyStopping (...)\n",
    "for  epoch in range(num_epochs):\n",
    "    # ciclo de entrenamiento\n",
    "    ...\n",
    "\n",
    "    # ciclo de validacion\n",
    "    ...\n",
    "\n",
    "    metrica_validacion = ...\n",
    "\n",
    "    if es.deberia_parar(metrica_validacion):\n",
    "        # se cumple el criterio de \"early stop\"\n",
    "        break\n",
    "```\n",
    "\n",
    "<center>Listing 1: Funcionamiento de la heurística Early Stopping</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "OfZwhwxCVK50"
   },
   "source": [
    "4. Programe la clase ``EarlyStopping``. Cuyo objetivo es implementar la heurística mencionada. Esta debe poseer los siguientes métodos:\n",
    "    * ``__init__(self, modo=’min’, paciencia=5, porcentaje=False, tol=0):`` donde los parámetros:\n",
    "\n",
    "        * ``modo``:  toma  valores  en ``’min’`` o ``’max’``.  Este  define  si  la  métrica  obtenida  en  el  conjunto de validación es considerada mejor al ser más pequeña o más grande según respectivamente.\n",
    "        * ``paciencia``: define el número de épocas en la que la métrica de validación puede empeorar sin detener el entrenamiento.\n",
    "        * ``porcentaje``: define si la comparación entre métricas de desempeño en validación, deben realizarse en términos relativos (como porcentaje de a la mejor métrica de desempeño observada) o absolutos.\n",
    "        * ``tol``: define la diferencia mínima que debe existir con respecto la mejor métrica de desempeño observada en validación, para considerar si existe un empeoramiento del desempeño y actualizar el valor del contador asociado a ``paciencia``.\n",
    "        \n",
    "     Se deja a criterio del equipo la definición de atributos para el correcto funcionamiento de la clase.  \n",
    "       \n",
    " * ``mejor(self, metrica_validacion):`` que compare la ``metrica_validacion`` con la mejor métrica de desempeño ya observada.  Dicha comparación debe realizarse considerando los parámetros ``modo``, ``porcentaje`` y ``tol``, y debe retornar ``True`` o ``False``.\n",
    " * ``deberia_parar(self, metrica_validacion):`` que llame al método ``mejor`` y retorne ``True`` cuando la cantidad de épocas en que ``metrica_validacion`` empeora con respecto a la mejor. métrica de desempeño observada sea igual a ``paciencia``. En caso contrario retorna ``False``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T03:34:56.106734Z",
     "start_time": "2020-07-16T03:34:56.096761Z"
    },
    "code_folding": [
     2,
     11,
     36
    ],
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "6hIPUllVyxv0"
   },
   "outputs": [],
   "source": [
    "class EarlyStopping():\n",
    "    \"\"\"Clase que para aplicar la heuristica señalada\"\"\"\n",
    "    def __init__(self, modo='min', paciencia=5, porcentaje=False, tol=0):\n",
    "        assert(modo in ['min','max'])\n",
    "        self.modo=modo\n",
    "        self.paciencia=paciencia\n",
    "        self.porcentaje=porcentaje\n",
    "        self.tol=tol\n",
    "        self.__metricas_obs=[]\n",
    "        self.vidas=paciencia\n",
    "            \n",
    "    def mejor(self, metrica_validacion, guardar=True):\n",
    "        \"\"\"metodo mejor: retorna True si la metrica a evaluar es mejor que\n",
    "        todas las anteriores registradas. Tambien se permite guardar o no \n",
    "        la metrica a evaluar\"\"\"\n",
    "        if self.__metricas_obs==[]:\n",
    "            if guardar:\n",
    "                self.__metricas_obs.append(metrica_validacion)\n",
    "            return True\n",
    "        elif self.modo=='min':\n",
    "            mejor = min(self.__metricas_obs)\n",
    "            if guardar:\n",
    "                self.__metricas_obs.append(metrica_validacion)\n",
    "            if self.porcentaje:\n",
    "                return 100*metrica_validacion/mejor - self.tol < 1\n",
    "            else:\n",
    "                return metrica_validacion - self.tol < mejor\n",
    "        else:\n",
    "            mejor = max(self.__metricas_obs)\n",
    "            if guardar:\n",
    "                self.__metricas_obs.append(metrica_validacion)\n",
    "            if self.porcentaje:\n",
    "                return 100*metrica_validacion/mejor + self.tol > 1\n",
    "            else:\n",
    "                return metrica_validacion + self.tol > mejor\n",
    "        \n",
    "    def deberia_parar(self, metrica_validacion):\n",
    "        \"\"\"Retorna True cuando al proceso se le agota la paciencia,\n",
    "        si el proceso mejora, reinicia la paciencia al valor original\"\"\"\n",
    "        if self.mejor(metrica_validacion):\n",
    "            self.vidas = self.paciencia\n",
    "            return False\n",
    "        else:\n",
    "            if self.vidas==1:\n",
    "                return True\n",
    "            else:\n",
    "                self.vidas -= 1\n",
    "                return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "9MsHx_AoVK6D"
   },
   "source": [
    "5. Implemente el ciclo de entrenamiento de la red ``VGG16DWSep`` utilizando una instancia de la clase ``EarlyStopping`` según el esquema de Listing 1 con sus parámetros por defecto y además vaya guardando los pesos del mejor modelo obtenido a través de las épocas. Para dicho ciclo de entrenamiento use:\n",
    "    * *Entropía cruzada* como función de costo.\n",
    "    * *Adam* cómo algoritmo de optimización, con parámetros ``lr=1e-4`` y ``weight_decay=1e-5``.\n",
    "    \n",
    "Reporte sus resultados en términos de *accuracy* y *f1-score*. Compruebe que obtiene resultados superiores a $,75$ y $,8$ respectivamente. *Hint:* Por la magnitud del problema se recomienda usar GPU. Recuerde que en ``Colaboratory`` tiene acceso gratuito a dicho recurso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Se utilizan algunas de las funciones del notebook S8:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T03:34:56.302214Z",
     "start_time": "2020-07-16T03:34:56.296230Z"
    },
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "XRmXkOOtxU7t"
   },
   "outputs": [],
   "source": [
    "def loss_batch(model, loss_func, xb, yb, opt=None):\n",
    "    \"\"\"Obtiene perdida por batches\"\"\"\n",
    "    loss = loss_func(model(xb), yb)\n",
    "\n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    return loss.item(), len(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T03:34:56.509478Z",
     "start_time": "2020-07-16T03:34:56.503516Z"
    },
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "922BBLUZxfsi"
   },
   "outputs": [],
   "source": [
    "def register(res_list):\n",
    "    '''Obtiene la perdida promedio y su desviacion estandar en batches.'''\n",
    "    \n",
    "    losses, nums = zip(*res_list)\n",
    "    \n",
    "    N = np.sum(nums)\n",
    "    loss_mean = np.sum(np.multiply(losses, nums))/N\n",
    "    loss_std = np.sqrt(np.sum(np.multiply((losses-loss_mean)**2, nums))/(N-1))\n",
    "    \n",
    "    return loss_mean, loss_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Se crea función que facilita proceso de evaluación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T03:34:56.704956Z",
     "start_time": "2020-07-16T03:34:56.698972Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def evaluar(model, xb):\n",
    "    \"\"\"Evalua un batch de observaciones en un modelo y retorna batch de \n",
    "    clases predichas\"\"\"\n",
    "    yb = model(xb).detach()\n",
    "    pb = torch.softmax(yb, dim=1)\n",
    "    return torch.argmax(pb, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Se modifica la funcion fit, para aplicar la heuristica de `EarlyStopping`, ademas guarda algunos resultados extras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T03:34:56.904516Z",
     "start_time": "2020-07-16T03:34:56.888465Z"
    },
    "code_folding": [
     7,
     12,
     14,
     19,
     65,
     87
    ],
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "AyU54i37sy7j"
   },
   "outputs": [],
   "source": [
    "def fit(epochs, model, loss_func, opt, train_dl, valid_dl, es=EarlyStopping(), only_print=True, print_leap = 1):\n",
    "    '''Fit - Entrena una red neuronal.\n",
    "\n",
    "      Funcion del notebook S8, donde es implementada la heuristica EarlyStopping\n",
    "      con sus valores por defecto y otras funcionalidades.\n",
    "    '''\n",
    "    # Dataframe donde se guardarán estadisticas del proceso de aprendizaje:\n",
    "    learning_data = pd.DataFrame(\n",
    "        columns=['epoch', 'train_mean', 'train_std', 'train_acc', 'train_f1',\n",
    "                 'val_mean', 'val_std', 'val_acc', 'val_f1'])\n",
    "    \n",
    "    # Usamos GPU si está disponible:\n",
    "    if torch.cuda.is_available():\n",
    "        dev = torch.device(\"cuda\")\n",
    "    else:\n",
    "        dev = torch.device(\"cpu\")\n",
    "        \n",
    "    model.to(dev)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Entrenamiento -------------------------------------------------------\n",
    "        train_res = []\n",
    "        train_eval = []\n",
    "        train_real = []\n",
    "        model.train()\n",
    "\n",
    "        for xb, yb in train_dl:\n",
    "            # Para entrenar se usa la funcion de perdida\n",
    "            loss_batch(model, loss_func, xb.to(dev), yb.to(dev), opt)\n",
    "\n",
    "            # Se almacenan métricas de rendimiento y perdida\n",
    "            train_res.append(loss_batch(model, loss_func, xb.to(dev), yb.to(dev)))\n",
    "            train_eval.append(evaluar(model, xb.to(dev)))\n",
    "            train_real.append(yb.detach())\n",
    "            \n",
    "        train_eval = torch.cat(train_eval)\n",
    "        train_real = torch.cat(train_real)\n",
    "\n",
    "        # Validacion ----------------------------------------------------------\n",
    "        model.eval()\n",
    "        val_res = []\n",
    "        val_eval = []\n",
    "        val_real = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in valid_dl:\n",
    "                # Se evaluan en la validacion metricas de rendimiento y perdida\n",
    "                val_res.append(loss_batch(model, loss_func, xb.to(dev), yb.to(dev)))\n",
    "                val_eval.append(evaluar(model,xb.to(dev)))\n",
    "                val_real.append(yb.detach())\n",
    "            \n",
    "        val_eval = torch.cat(val_eval)\n",
    "        val_real = torch.cat(val_real)\n",
    "        \n",
    "        # Se recopilan las estadisticas del proceso:\n",
    "        val_loss, val_std = register(val_res)\n",
    "        val_acc = accuracy_score(val_eval.cpu(), val_real.cpu())\n",
    "        val_f1 = f1_score(val_eval.cpu(), val_real.cpu())\n",
    "        train_loss, train_std = register(train_res)\n",
    "        train_acc = accuracy_score(train_eval.cpu(), train_real.cpu())\n",
    "        train_f1 = f1_score(train_eval.cpu(), train_real.cpu())\n",
    "\n",
    "        if epoch % print_leap == 0:\n",
    "            print('Epoca:', epoch, '- val:', val_loss, '- train:', train_loss)\n",
    "\n",
    "        learning_data = learning_data.append(\n",
    "            {\n",
    "                'epoch': epoch,\n",
    "                'train_mean': train_loss,\n",
    "                'train_std': train_std,\n",
    "                'train_acc': train_acc,\n",
    "                'train_f1': train_f1,\n",
    "                'val_mean': val_loss,\n",
    "                'val_std': val_std,\n",
    "                'val_acc': val_acc,\n",
    "                'val_f1': val_f1\n",
    "            },\n",
    "            ignore_index=True)\n",
    "        \n",
    "        if es.mejor(val_loss, guardar=False):\n",
    "            # Se guardan los pesos del mejor modelo del momento\n",
    "            mejores_pesos = model.state_dict()\n",
    "        \n",
    "        if es.deberia_parar(val_loss):\n",
    "            # Si se agota la paciencia, se detiene el proceso:\n",
    "            break        \n",
    "\n",
    "    if only_print:\n",
    "        print('Proceso terminado')\n",
    "        return mejores_pesos\n",
    "    else:\n",
    "        return learning_data, mejores_pesos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Definimos los objetos necesarios para realizar el entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T03:34:57.309876Z",
     "start_time": "2020-07-16T03:34:57.303890Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(1929)\n",
    "\n",
    "\"\"\"Se define función de perdida y optimizador\"\"\"\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "opt = optim.Adam(mdl.parameters(), lr=1e-4, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T05:01:05.041536Z",
     "start_time": "2020-07-16T03:34:57.495166Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Se entrena el modelo con earlystopping\"\"\"\n",
    "learning_data, pesos = fit(30, mdl, loss_func, opt, train_DL, valid_DL, only_print=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Se guardan los mejores pesos de la red en `modelo.h5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T05:08:16.682124Z",
     "start_time": "2020-07-16T05:08:15.412392Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "torch.save(pesos, \"data/modelos/modelo.h5\")\n",
    "torch.save(learning_data, \"data/modelos/df_aprendizaje.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Se puede encontrar el archivo <a href=https://drive.google.com/drive/u/2/folders/1UZzh-Cv99uxZtLEBwp0p8qndJCusiR0m>acá</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T20:14:20.314990Z",
     "start_time": "2020-07-16T20:14:18.325799Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mdl = VGG16DWSep()\n",
    "mdl.load_state_dict(torch.load(\"data/modelos/modelo.h5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Se evalua en el conjunto de prueba y se reportan las metricas accuracy y f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T05:16:32.765302Z",
     "start_time": "2020-07-16T05:16:21.655520Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(1929)\n",
    "\n",
    "test_eval = []\n",
    "test_real = []\n",
    "\n",
    "\n",
    "if torch.cuda.is_available(): dev = torch.device('cuda')\n",
    "else: dev = torch.device('cpu')\n",
    "    \n",
    "mdl.to(dev)\n",
    "mdl.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for xb, yb in test_DL:\n",
    "        test_eval.append(evaluar(mdl, xb.to(dev)))\n",
    "        test_real.append(yb.detach())\n",
    "\n",
    "test_eval = torch.cat(test_eval)\n",
    "test_real = torch.cat(test_real)\n",
    "print(\"accuracy score:\", accuracy_score(test_real.cpu(), test_eval.cpu()))\n",
    "print(\"f1 score:\", f1_score(test_real.cpu(), test_eval.cpu()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Se defin ahora una funcion para graficar el proceso de aprendizaje (basado en funcion de notebook S8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T05:17:47.568384Z",
     "start_time": "2020-07-16T05:17:47.558409Z"
    },
    "code_folding": [
     10,
     23
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_learning_curves(learning_data, metrica='Accuracy', leaps = 1):\n",
    "    '''Genera curvas de aprendizaje dado data dataframe resultado de fit().'''\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=[10, 7])\n",
    "    ax.grid()\n",
    "    \n",
    "    epcs = learning_data['epoch'][::leaps]\n",
    "\n",
    "    if learning_data.columns.size==3:\n",
    "        ax.plot(epcs,\n",
    "                learning_data.iloc[:,2][::leaps],\n",
    "                'o--',\n",
    "                color=\"g\",\n",
    "                label=\"Validation\")    \n",
    "\n",
    "        ax.plot(epcs,\n",
    "                learning_data.iloc[:,1][::leaps],\n",
    "                'o--',\n",
    "                color=\"r\",\n",
    "                label=\"Train\")\n",
    "\n",
    "    else:\n",
    "        ax.plot(epcs,\n",
    "            learning_data['val_mean'][::leaps],\n",
    "            'o--',\n",
    "            color=\"g\",\n",
    "            label=\"Validation\")    \n",
    "\n",
    "        ax.plot(epcs,\n",
    "                learning_data['train_mean'][::leaps],\n",
    "                'o--',\n",
    "                color=\"r\",\n",
    "                label=\"Train\")\n",
    "        \n",
    "        val_loss_lower = (learning_data['val_mean'] -\n",
    "                          learning_data['val_std'])[::leaps]\n",
    "\n",
    "        val_loss_upper = (learning_data['val_mean'] +\n",
    "                          learning_data['val_std'])[::leaps]\n",
    "\n",
    "        train_loss_lower = (learning_data['train_mean'] -\n",
    "                            learning_data['train_std'])[::leaps]\n",
    "        train_loss_upper = (learning_data['train_mean'] +\n",
    "                            learning_data['train_std'])[::leaps]\n",
    "        ax.fill_between(epcs, val_loss_lower, val_loss_upper, alpha=0.1, color='g')\n",
    "        ax.fill_between(epcs, train_loss_lower, train_loss_upper, alpha=0.1, color='r')\n",
    "    \n",
    "    ax.set_title('Curva de Aprendizaje', fontsize=25)\n",
    "    ax.set_xlabel('Epocas', fontsize=15)\n",
    "    ax.set_ylabel(metrica, fontsize=15)\n",
    "    ax.legend()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T05:17:51.016665Z",
     "start_time": "2020-07-16T05:17:51.008677Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_acc = learning_data[['epoch', 'train_acc', 'val_acc']]\n",
    "data_f1 = learning_data[['epoch', 'train_f1', 'val_f1']]\n",
    "data_ce = learning_data[['epoch', 'train_mean', 'train_std', 'val_mean', 'val_std']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T05:18:59.406128Z",
     "start_time": "2020-07-16T05:18:59.116584Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig = show_learning_curves(data_ce, 'Cross Entropy')\n",
    "fig.savefig('data/plots/learn_ce.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T05:19:03.149154Z",
     "start_time": "2020-07-16T05:19:02.871895Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig = show_learning_curves(data_acc, 'Accuracy Score')\n",
    "fig.savefig('data/plots/learn_acc.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T05:19:06.959495Z",
     "start_time": "2020-07-16T05:19:06.676228Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig = show_learning_curves(data_f1, 'F1 Score')\n",
    "fig.savefig('data/plots/learn_f1.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "QkaL5WSzVK6e"
   },
   "source": [
    "6. Implemente aumentación de datos en el conjunto de prueba: para una observación $x_i$, obtenga $d$ muestras$\\{x^{(j)}_i\\}^d_{j=1}$para calcular la predicción $y_i=arg max_{k=1,2}\\sum_{j=1,...,d}P(x^{(j)}_i\\in C_k)$, donde $P$ representa la probabilidad  asociada  la  predicción de su red.  Discuta  si es correcto o no realizar esto y soporte su argumento con los resultados obtenidos en términos de *accuracy* y *f1-score*.\n",
    "\n",
    "*Hint:* Puede ser útil implementar una clase que herede de ``torch.utils.data.Sampler`` y que reciba como parámetros la cantidad de muestras para una misma observación $x_i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T20:20:34.588782Z",
     "start_time": "2020-07-16T20:20:33.596877Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Se carga el modelo entrenado\"\"\" \n",
    "mdl = VGG16DWSep()\n",
    "mdl.load_state_dict(torch.load('data/modelos/modelo.h5'))\n",
    "if torch.cuda.is_available(): dev = torch.device('cuda')\n",
    "else: dev = torch.device('cpu')\n",
    "mdl.to(dev);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T20:20:34.630670Z",
     "start_time": "2020-07-16T20:20:34.624686Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def evaluar2(model, xb):\n",
    "    \"\"\"Funcion para evaluar batches {x_i^j}_{j=1}^d, segun \n",
    "    y_i = argmax_{k=0,1} \\sum_{j=1}^d (P(x_i^j \\in C_k))\"\"\"\n",
    "    yb = model(xb).detach()\n",
    "    pb = torch.softmax(yb, dim=1)\n",
    "    s  = torch.sum(pb, dim=0)\n",
    "    return torch.argmax(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T20:20:35.301986Z",
     "start_time": "2020-07-16T20:20:35.298020Z"
    },
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "ksilzWTYm3pA"
   },
   "outputs": [],
   "source": [
    "class AumentaSampler(torch.utils.data.Sampler):\n",
    "    \"\"\"Sampler que dado un objeto DatasetFolder y un int d, genera muestras\n",
    "    de tamaño d para cada observación i en el dataset\"\"\"\n",
    "    def __init__(self, dataset_folder, d):\n",
    "        self.dataset = dataset_folder\n",
    "        self.length = len(dataset_folder.targets)\n",
    "        self.num_samples = d\n",
    "    def __iter__(self):\n",
    "        obs = np.random.randint(0, self.length, self.length)\n",
    "        sample = [i for i in obs for j in range(self.num_samples)]\n",
    "        return iter(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T20:20:37.245435Z",
     "start_time": "2020-07-16T20:20:37.237456Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Se utilizan las transformaciones de la parte 1 para aumentar los datos\"\"\"\n",
    "\n",
    "def loader(input):\n",
    "    '''Funcion que carga la imagen, si es de 1 canal la pasa a 3 canales '''\n",
    "    image = Image.open(input)\n",
    "    img = image.split()\n",
    "    if len(img) == 1:\n",
    "        return Image.merge('RGB', (img[0], img[0], img[0]))\n",
    "    else:\n",
    "        return image\n",
    "\n",
    "def ajust_brillo(img):\n",
    "    '''Multiplica los valores de cada pixel por un número aleatorio entre 1.2 y 1.5 '''\n",
    "    return img.point(lambda i: i*np.random.uniform(1.2,1.5))\n",
    "\n",
    "transf = transforms.Compose([transforms.Resize([224, 224]),\n",
    "                             transforms.ColorJitter(brightness=(0,1)),\n",
    "                             transforms.RandomHorizontalFlip(p=0.5),\n",
    "                             transforms.RandomRotation(degrees=(-20,20)),\n",
    "                             transforms.Lambda(lambda x: ajust_brillo(x)),\n",
    "                             transforms.ToTensor()\n",
    "                            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T20:20:38.170105Z",
     "start_time": "2020-07-16T20:20:38.158168Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Se definen los objetos necesarios para realizar el procedimiento\"\"\"\n",
    "d=4\n",
    "data_test = DatasetFolder('data/chest_xray/test', \n",
    "                          loader = loader,\n",
    "                          extensions=('jpeg'), \n",
    "                          transform=transf)\n",
    "test_aum = DataLoader(data_test, \n",
    "                      batch_size=d, \n",
    "                      sampler = AumentaSampler(data_test,d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T20:21:24.425226Z",
     "start_time": "2020-07-16T20:20:40.110766Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Se evalua el conjunto test, siguiendo esta metodología\"\"\"\n",
    "\n",
    "y_pred=[]\n",
    "y_true=[]\n",
    "mdl.to(dev)\n",
    "mdl.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for xb, yb in test_aum:\n",
    "        y_pred.append(evaluar2(mdl, xb.to(dev)))\n",
    "        y_true.append(yb.detach()[0])\n",
    "\n",
    "y_pred=torch.tensor(y_pred)\n",
    "y_true=torch.tensor(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T20:21:47.496816Z",
     "start_time": "2020-07-16T20:21:47.488835Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(\"accuracy score:\", accuracy_score(y_true.cpu(), y_pred.cpu()))\n",
    "print(\"f1 score:\", f1_score(y_true.cpu(), y_pred.cpu()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "id": "DYiMJEBIVK6k"
   },
   "source": [
    "## P3. Interpretabilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "qZIMlo8VVK6n"
   },
   "source": [
    "El objetivo de esta pregunta es que implemente un modelo auxiliar de interpretabilidad local sobre laspredicciones que genera una red neuronal. Esto consiste en generar perturbaciones sobre datos de entrada, con el fin de comprender la importancia de las variables en los procesos de predicción. Para ello deberá implementar el método LIME (**L**ocal**I**nterpretable**M**odel-**A**gnostic**E**xplanations).\n",
    "\n",
    "### Desarrollo teórico\n",
    "El procedimiento LIME consiste en una metodología diseñada para otorgar *interpretabilidad* a modelos de aprendizaje que suelen ser denotados como “caja negra”. Por interpretabilidad se entiende, la capacidad deestablecer relaciones claras entre las variables de un fenómeno y la respuesta que producen. LIME es “agnóstico en el modelo”, esto se refiere a que pueda ser utilizado para cualquier tipo de modelo de predicción.\n",
    "\n",
    "La idea central de LIME consiste en aproximar localmente el comportamiento de un predictor, utilizando un modelo que sea interpretable como por ejemplo regresión lineal o arboles de decisión. En términos concretos, dada una instancia a predecir $x\\in\\mathbb{R}^d$ (dato de entrada), se utilizará un vector $x′\\in\\{0,1\\}^{d'}$como representación interpretable. Se define así, una **explicación** cómo un modelo $g\\in G$, donde $G$ corresponde a una familia de modelos potencialmente interpretable, el dominio de cada $g\\in G$ será $\\{0,1\\}^{d'}$. Para asegurar que la aproximación buscada sea interpretable por un humano, se utiliza una medida  de complejidad $\\Omega(g)$ sobre cada $g\\in G$, considerando el grado de complejidad en contraposición a la interpretabilidad de un modelo.\n",
    "\n",
    "Sea un modelo predictor $f:\\mathbb{R}^d\\to \\mathbb{R}$, sea además $x\\in\\mathbb{R}^d$ en el conjunto de datos de entrada, y $x′\\in\\{0,1\\}^{'d}$ su representación interpretable. Para $x$ se define $\\pi_x(z'):\\{0,1\\}^{'d} \\to\\mathbb{R}$ como una medida de similitud entre $x′$ y $z′\\in \\{0,1\\}^{′d}$. Finalmente, se define $L(f,g,\\pi_x)$ en una vecindad inducida localmente por $\\pi_x$. Para asegurar interpretabilidad y fidelidad local (asociada a $x$), la explicación producida por LIME se obtiene resolviendo la siguiente expresión:\n",
    "\n",
    "\\begin{equation}\n",
    "\\xi(x) = arg min_{g\\in G}\\mathcal{L}(f,g,\\pi_x) + \\Omega(g)\n",
    "\\label{eqn:1}  \\tag{1}\n",
    "\\end{equation}\n",
    "\n",
    "En esta pregunta, se utilizará regresión logística cómo familia de explicaciones $G$, es decir para cada $g\\in G$ este será de la forma $g(x′) =\\sigma(w_g\\cdot x′)$. Cómo función de fidelidad $\\mathcal{L}$ se usa el la verosimilitud asociada a la regresión logística, ponderada localmente por $\\pi_x$, es decir:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathcal{L}(f,g,\\pi_x) =\\sum_{z,z′}\\pi_x(z)(f(z) log(g(z′)) + (1−f(z)) log(1−g(z′))\n",
    "\\label{eqn:2} \\tag{2}\n",
    "\\end{equation}\n",
    "\n",
    "En este caso $\\pi_x$ será un kernel exponencial definido por una medida de similitud, se utilizará la distancia coseno:\n",
    "\n",
    "\\begin{align}\n",
    "\\pi_x(z′) &= \\exp(−d(x′,z′)^2/\\sigma^2)\\tag{3} \\\\ \n",
    "d(x′,z′) &= 1−\\frac{x′\\cdot z′}{‖x′‖‖z′‖}\n",
    "\\label{eqn:4}\\tag{4}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NuCt1VnJyxwD"
   },
   "source": [
    "Implemente los paso iniciales para trabajos con LIME, para esto:\n",
    "1. Instancie un objeto ``torchvision.transforms.Compose``, este opera sobre imágenes ``PIL`` y le aplique las siguientes transformaciones:\n",
    "    * Escalamiento de la imagen a un tamaño de $229\\times 229$ píxeles.\n",
    "    * Opere por medio de ``CenterCrop(299)``.\n",
    "    * Transforme la imagen en un objeto ``Tensor``.\n",
    "    * Normalice con las medias ``[0.485, 0.456, 0.406]`` y, desviaciones estándar ``[0.229, 0.224, 0.225]``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mmFrreWayxwE"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import torchvision.transforms as torch_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a7mJLgL6zGL8"
   },
   "outputs": [],
   "source": [
    "# Se define la Media de la transformación\n",
    "mean_transform = [0.485, 0.456, 0.406]\n",
    "# std de la transformación\n",
    "std_transform = [0.229, 0.224, 0.225]\n",
    "# Número de center crops\n",
    "n_centercrop = 299\n",
    "# parámetros de escalamiento de la figura\n",
    "x_resize = 299\n",
    "y_resize = 299\n",
    "\n",
    "\n",
    "# Se crea la 'pipeline' de un transformador de imagen cualquiera\n",
    "image_transformer =  torch_transforms.Compose([\n",
    "                                              torch_transforms.Resize((x_resize,y_resize)),\n",
    "                                              torch_transforms.CenterCrop(n_centercrop),\n",
    "                                              torch_transforms.ToTensor(),\n",
    "                                              torch_transforms.Normalize(mean_transform, std_transform)\n",
    "                                              ])\n",
    "\n",
    "f_half_image_transformer =  torch_transforms.Compose([\n",
    "                                              torch_transforms.Resize((x_resize,y_resize)),\n",
    "                                              torch_transforms.CenterCrop(n_centercrop)\n",
    "                                              ])\n",
    "\n",
    "s_half_image_transformer =  torch_transforms.Compose([\n",
    "                                              torch_transforms.ToTensor(),\n",
    "                                              torch_transforms.Normalize(mean_transform, std_transform)\n",
    "                                              ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b76b-sGZyxwK"
   },
   "source": [
    "2. Cargue la red ``inception_v3`` entrenada sobre *imageNet* (en ``Pytorch``). Utilice esta red para hacer predicción sobre una imagen de control a la cual se aplican las transformaciones antes definidas. Obtenga la clase más probable asignada por la red. \n",
    "\n",
    "*Hint:* Puede ser ́útil la función ``decode_predictions``del módulo ``keras.applications.imagenet_utils`` sobre las predicciones de la red cargada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mYzzzzoBq04j"
   },
   "outputs": [],
   "source": [
    "# Definimos de primeras en qué device trabajaremos\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RV08FCt9yxwL"
   },
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "# Se carga la red entrenada inception_v3\n",
    "model_inception = models.inception_v3( pretrained=True)\n",
    "\n",
    "# Reactivamos la red\n",
    "model_inception.eval()\n",
    "model_inception.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "83ZyIRK4kx0L",
    "outputId": "051965a9-9460-4a9b-e9e6-8f921df840f8"
   },
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "summary(model_inception, (3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DdiPDN8Il0fp"
   },
   "outputs": [],
   "source": [
    "# Parámetros Generales para gráficos\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 30})      \n",
    "plt.rc('axes', labelsize=20)\n",
    "plt.rc('legend', fontsize=18)  \n",
    "plt.rc('xtick', labelsize=14) \n",
    "plt.rc('ytick', labelsize=14) \n",
    "plt.rcParams['axes.titlesize'] = 25\n",
    "plt.rcParams[\"figure.figsize\"] = (15,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uS3BF5RscffQ"
   },
   "outputs": [],
   "source": [
    "# Funciones auxiliares\n",
    "\n",
    "# Visualización de imágenes\n",
    "def plot_image(image, title):\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    ax.imshow(image)\n",
    "    ax.set_title(title, size = 20)\n",
    "    ax.set_ylabel('Alto')\n",
    "    ax.set_xlabel('Ancho')\n",
    "\n",
    "def plot_multiple_images(vec_image, title = 'Plot Imagen Transformada'):\n",
    "    fig, axs = plt.subplots(1, 3)\n",
    "    for i in range(3):\n",
    "        image = vec_image[i, :, :]\n",
    "        axs[i].imshow(image)\n",
    "        axs[i].set_title('Canal N°{}'.format(i+1))\n",
    "  \n",
    "    fig.suptitle(title)\n",
    "\n",
    "def plot_multiple_images_control(image,vec_image):\n",
    "    fig, axs = plt.subplots(1, 2, figsize = (8,4))\n",
    "    for i in range(2):\n",
    "        if i ==0:\n",
    "            axs[i].imshow(image)\n",
    "            axs[i].set_title('Imagen Original')\n",
    "            axs[i].set_ylabel('Alto')\n",
    "            axs[i].set_xlabel('Ancho')\n",
    "        else:\n",
    "            image = vec_image[i-1, :, :]\n",
    "            axs[i].imshow(image)\n",
    "            axs[i].set_title('Canal N°{} Tranformación'.format(i))\n",
    "            axs[i].set_xlabel('Ancho')\n",
    "    #fig.suptitle(title)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "colab_type": "code",
    "id": "-q-LHyz35FWn",
    "outputId": "448cab7d-a715-49c9-cbf0-9bb26080531b"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Fijamos la semilla\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "'''\n",
    "Las siguientes líneas comentadas son por si quieren cargar una imagen desde una\n",
    "URL\n",
    "\n",
    "# from io import BytesIO\n",
    "# import requests\n",
    "\n",
    "# url = 'https://farm4.static.flickr.com/3024/3003973173_765f89510b.jpg'\n",
    "# image_url = requests.get(url)\n",
    "# test_image_imagenet = Image.open(BytesIO(image_url.content))\n",
    "'''\n",
    "\n",
    "drive_path = 'data/images/'\n",
    "\n",
    "image_path = drive_path + 'tiger_2.jpg'\n",
    "\n",
    "# Se 'abre' la imagen\n",
    "test_image = Image.open(image_path)\n",
    "\n",
    "# Se aplica el transformador creado\n",
    "test_image_transformed = image_transformer(test_image)\n",
    "\n",
    "# Visualizamos la imagen y sus transformaciones\n",
    "plot_multiple_images_control(test_image,test_image_transformed)\n",
    "plt.savefig(drive_path + 'imagen_leon_transformaciones.pdf', format = 'pdf', dpi = 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ScXVjz6CIDMs"
   },
   "outputs": [],
   "source": [
    "# Generamos la predicción sobre la imagen\n",
    "with torch.no_grad():\n",
    "    test_image_transformed = test_image_transformed.to(device)\n",
    "    pred_image = model_inception(test_image_transformed.unsqueeze(0))\n",
    "    aux_pred = np.expand_dims(pred_image.cpu().detach().numpy(), axis=0)\n",
    "    label_predict = decode_predictions(aux_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "co2gimBSdwn4",
    "outputId": "a31d5c01-1c14-4625-a4ec-613b12eb2aba"
   },
   "outputs": [],
   "source": [
    "# Mostramos los resultados \n",
    "label_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WRQDB7plFShf"
   },
   "source": [
    "Notamos que el top 5 de los labels con más probabilidades acumulan aproximadamente un total de 23 porciento. Todos los labels son semejantes de cierta forma con el León, como lo son el tigre y el cheetah, felinos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hlACrC5WyxwQ"
   },
   "source": [
    "3. Segmente la imagen de control utilizando la función ``slic`` del módulo ``skimage.segmentation``, para los parámetros ``start_label=0``, ``n_segments=80``. El resultado de esta segmentación es un arreglo de dimensión $299\\times 299$ que asigna una categoría para cada píxel de la imagen procesada. Todos los píxeles en la imagen que comparten etiqueta conforman un super-píxel dentro de la imagen. Utilice la función ``mark_boundaries`` del módulo ``skimage.segmentationen`` conjunción con ``imshow`` del módulo ``skimage.io`` para visualizar los bordes inducidos por el conjunto de super-píxeles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FUtBqjS-CG7C"
   },
   "outputs": [],
   "source": [
    "# Lo primero es obtener de vuelta la imagen escalada desde los tensores\n",
    "# Para poder aplicar slic\n",
    "\n",
    "# 'Des-estandarizamos la imagen\n",
    "im_reboot = test_image_transformed.cpu()*torch.tensor(std_transform).view(3,1,1)\n",
    "im_reboot = im_reboot + torch.tensor(mean_transform).view(3,1,1)\n",
    "\n",
    "# Transformamos la imagen a PIL\n",
    "im_reboot = torch_transforms.ToPILImage(mode = 'RGB')(im_reboot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 345
    },
    "colab_type": "code",
    "id": "y1mcOEB3Bxa_",
    "outputId": "36a561f7-2322-40b8-e2eb-2e9ec77a1e4b"
   },
   "outputs": [],
   "source": [
    "from skimage.segmentation import slic\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from skimage import io\n",
    "\n",
    "# Dividimos en 80 segmentos\n",
    "n_segments = 80\n",
    "start_label = 0\n",
    "\n",
    "# Segmentamos la imágen\n",
    "segmented_image =  slic(im_reboot, n_segments = n_segments) \n",
    "\n",
    "# Visualizamos la segmentación generadaplt\n",
    "plt.subplots()\n",
    "io.imshow(mark_boundaries(im_reboot, segmented_image))\n",
    "plt.title('Imagen de control segmentada')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GB35zCMkyxwZ"
   },
   "source": [
    "Al representar una imagen $x$ por medio de la presencia y ausencia de los super-píxeles se logra una representación interpretable $x′$ según un vector de entradas binarias.\n",
    "\n",
    "Genere perturbaciones en la imagen de control, para esto siga los siguientes pasos:\n",
    "4. Defina un número de *perturbaciones* a realizar (al menos $1,000$). Cada perturbación consiste en arreglo binario, donde cada componente es asociada a un super-píxel. Estos arreglos serán las representaciones interpretables de la imagen de control ($x′$ asociado a $x$). Considere cada entrada de su arreglo de perturbaciones como una variable aleatoria ``Bernoulli`` con $p= 0,5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Orj4DoSyxwa"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import bernoulli\n",
    "\n",
    "# Fijamos la semillas para asegurar replicabiliadad\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Definimos los parámetros a utilizar\n",
    "p = 0.5\n",
    "n_perturbaciones = 2000\n",
    "n_superpixeles = len(np.unique(segmented_image))\n",
    "\n",
    "# Creamos la matriz de perturbaciones \n",
    "matriz_perturbaciones = bernoulli.rvs(p,size = n_superpixeles * n_perturbaciones)\n",
    "# Le damos la forma de matriz, donde cada columna representa un vector de \n",
    "# perturbaciones según el número de superpixeles de la imagen\n",
    "matriz_perturbaciones = matriz_perturbaciones.reshape((n_superpixeles, n_perturbaciones))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MkJLGQo7yxwg"
   },
   "source": [
    "5. Genere tantas versiones perturbadas de la imagen de control como perturbaciones haya construido. Obtener una imagen perturbada consiste en asignar el valor $0$ en cada canal de color en aquellos píxeles cuyos super-píxeles asociados tengan su componente nula en el vector de perturbaciones. Obtenga una visualización de una imagen perturbada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wg2qvjLWdpPk"
   },
   "outputs": [],
   "source": [
    "def Generador_Pert_Images(image_path, n_iter, matriz_perturbaciones, \n",
    "                          slic_results, n_centercrop, f_half_image,\n",
    "                          s_half_image, vgg = False):\n",
    "    '''\n",
    "    Generador de n_iter perturbaciones según una matriz_perturbaciones dada de una imagen\n",
    "\n",
    "    image_path: PATH de carga de la imagen\n",
    "    n_iter: Número de iteraciones\n",
    "    matriz_perturbaciones: Matriz de perturbaciones \n",
    "    slic_results: resultados de alguna segmentacion de la imagen con .slic\n",
    "    n_centercrop: valor de ancho de una imagen cuadrada (antes del typo era con centercrop)\n",
    "    transformer: Transformador de imagens, torch.transforms.compose\n",
    "\n",
    "    return: vector de imagenes en formato tensor\n",
    "    '''\n",
    "    vec_images = []\n",
    "    if vgg:\n",
    "        image = Image.open(image_path)\n",
    "        img = image.split()\n",
    "        if len(img) == 1:\n",
    "            image = Image.merge('RGB', (img[0], img[0], img[0]))\n",
    "        else:\n",
    "            pass    \n",
    "    else:\n",
    "        image = Image.open(image_path)\n",
    "\n",
    "    image = np.array(f_half_image(image))\n",
    "\n",
    "    for i in range(n_iter):\n",
    "        vec_images.append(np.copy(image))\n",
    "\n",
    "    lista_indices = np.unique(slic_results)\n",
    "\n",
    "    for i in range(n_iter):\n",
    "        image = vec_images[i]\n",
    "        vec_perturbaciones = matriz_perturbaciones[:, i]\n",
    "        lista_pert = list(zip(*np.argwhere(vec_perturbaciones==0)))[0]\n",
    "        a = np.copy(slic_results)\n",
    "        for k in lista_indices:\n",
    "            if k in lista_pert:\n",
    "                a[a == k] = 0\n",
    "            else:\n",
    "                a[a == k] = 1\n",
    "        a = np.repeat(a[:, :, np.newaxis], 3, axis=2)\n",
    "        image = np.multiply(image, a)\n",
    "        image = Image.fromarray(image.astype('uint8'), 'RGB')\n",
    "          \n",
    "        vec_images[i] = s_half_image(image)\n",
    "\n",
    "    return(vec_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PRiwl77n9mVA"
   },
   "outputs": [],
   "source": [
    "# Generamos el vector de transformaciones de la imagen de control\n",
    "vec_images = Generador_Pert_Images(image_path,\n",
    "                                   n_perturbaciones,\n",
    "                                   matriz_perturbaciones,\n",
    "                                   segmented_image,\n",
    "                                   n_centercrop,\n",
    "                                   f_half_image_transformer,\n",
    "                                   s_half_image_transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1E7P2G5TI1l2"
   },
   "outputs": [],
   "source": [
    "\n",
    "def plot_slic_image_vec(control_image, slic_control_image,\n",
    "                        vec_image):\n",
    "    # 'Des-estandarizamos la imagen\n",
    "    rec_image = vec_image.cpu()*torch.tensor(std_transform).view(3,1,1)\n",
    "    rec_image = rec_image + torch.tensor(mean_transform).view(3,1,1)\n",
    "\n",
    "    # Transformamos la imagen a PIL\n",
    "    rec_image = torch_transforms.ToPILImage(mode = 'RGB')(rec_image)\n",
    "    fig, axs = plt.subplots(nrows=2, ncols=2, figsize = (8,9))\n",
    "\n",
    "    axs[0,0].imshow(control_image)\n",
    "    axs[0,0].set_title('Imagen Original')\n",
    "    axs[0,0].set_ylabel('Alto')\n",
    "\n",
    "    axs[0,1].imshow(mark_boundaries(control_image, slic_control_image))\n",
    "    axs[0,1].set_title('Segmentación')\n",
    "\n",
    "    image = vec_image[0, :, :]\n",
    "    axs[1,0].imshow(image)\n",
    "    axs[1,0].set_title(' Trans. y Pert.')\n",
    "    axs[1,0].set_xlabel('Ancho')\n",
    "    axs[1,0].set_ylabel('Alto')\n",
    "\n",
    "    axs[1,1].imshow(rec_image)\n",
    "    axs[1,1].set_title('Perturbación')\n",
    "    axs[1,1].set_xlabel('Ancho')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 591
    },
    "colab_type": "code",
    "id": "PZgHlFzYKRF0",
    "outputId": "084be13a-b092-4c8b-d8a7-3d91c409a72f"
   },
   "outputs": [],
   "source": [
    "# Visualizamos la imagen segmentada y una perturbacion cualquiera\n",
    "plot_slic_image_vec(im_reboot, segmented_image, vec_images[10])\n",
    "plt.savefig(drive_path + 'leon_transformado_perturbado.pdf', format = 'pdf', dpi = 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 346
    },
    "colab_type": "code",
    "id": "YQny30tIWnme",
    "outputId": "ec695485-00c8-4120-c28e-a11397f53194"
   },
   "outputs": [],
   "source": [
    "plot_multiple_images(vec_images[1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v-RlI4-Myxwm"
   },
   "source": [
    "6. Haga predicción sobre las imágenes perturbadas utilizando la red ``inception_v3``. Asocie el valor $1$ como etiqueta a las imágenes perturbadas que sean clasificadas a la misma categoría de la imagen de control y $0$ en caso contrario, el arreglo binario correspondiente se denotará $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Dz-nlWwXBjs"
   },
   "outputs": [],
   "source": [
    "def create_y_vector(unique_label, model, vec_images, vgg = False):\n",
    "    # pred_inception = model(torch.from_numpy(vec_images))\n",
    "    # Se muere la ram si hago lo anterior\n",
    "    '''\n",
    "    Función que crea el vector y\n",
    "\n",
    "    unique_label: label único, string predecido\n",
    "    model: modelo de red utilizado\n",
    "    vec_images: vector de imágenes perturbada en formato tensor\n",
    "    vgg: si es true, indica que el modelo es correspondiente a la Red VGG\n",
    "\n",
    "    return:\n",
    "    array de 1,0\n",
    "    '''\n",
    "    y_vec = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(n_perturbaciones):\n",
    "            if vgg:\n",
    "                pred_image_v = model(vec_images[i].to(device).unsqueeze(0))\n",
    "                aux_pred_v = np.expand_dims(pred_image_v.cpu().detach().numpy(), axis=0)\n",
    "                y_vec.append(np.argmax(np.array(aux_pred_v)[0][0]))\n",
    "            else:     \n",
    "                #pred_inception  = model(torch.from_numpy(vec_images[i]).to(device).unsqueeze(0))\n",
    "                pred_inception  = model(vec_images[i].to(device).unsqueeze(0))\n",
    "                labels_prediction = decode_predictions(pred_inception.cpu().detach().numpy(), top = 1)\n",
    "                label_pred = labels_prediction[0][0][1]\n",
    "                y_vec.append(int(unique_label == label_pred))\n",
    "                #y_vec.append(label_pred)\n",
    "    return np.array(y_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zt1ztU7Jz1Rd"
   },
   "outputs": [],
   "source": [
    "# Creamos el vector solicitado\n",
    "y = create_y_vector(label_predict[0][0][1], model_inception, vec_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "Rc1HO76TvyF-",
    "outputId": "3d642c7d-ee87-49c0-e3ee-f6147ec8d9e6"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Realizamos un conteo de los casos positivos y negativos\n",
    "pd.Series(y).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tpa7aHDXMeOg"
   },
   "source": [
    "Notamos que las clases encontradas no se encuentran en un gran desbalanceo. Con las perturbaciones se predijo un total de 374 veces 'bien' la imagen. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t4Pnt_c_yxwt"
   },
   "source": [
    "7. Calcule $\\pi_x$ según la expresión **(3)**. Para ello, obtenga la distancia de coseno entre las perturbaciones asociadas a cada imagen perturbada y el vector de perturbación de la imagen de control $x$ según lo indica **(4)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B1vRPQ0yyxwu"
   },
   "outputs": [],
   "source": [
    "sigma = 0.25\n",
    "\n",
    "def pi_x(x,z):\n",
    "    dxz = 1 - (x@z)/((np.sqrt(x@x))*(np.sqrt(z@z)))\n",
    "    return np.exp(- dxz/sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hi-9NwdPqjJb"
   },
   "outputs": [],
   "source": [
    "def create_pi_vector(n_superpixeles, matriz_perturbaciones):\n",
    "    x = np.ones((n_superpixeles))\n",
    "    vec_pi_x = []\n",
    "    for i in range(n_perturbaciones):\n",
    "        z = matriz_perturbaciones[:, i]\n",
    "        vec_pi_x.append(pi_x(x,z))\n",
    "    return vec_pi_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VA1yfiTMf_qF"
   },
   "outputs": [],
   "source": [
    "vec_pi_x = create_pi_vector(n_superpixeles, matriz_perturbaciones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ILlUTVEKyxwy"
   },
   "source": [
    "Una vez obtenido un conjunto de representaciones para la imagen de control $x$ y el vector de pesos asociados $\\pi_x$, se pasa a minimizar la función de fidelidad, para esto:\n",
    "8. Genere un conjunto de entrenamiento $D_p$. Este consta de vectores de perturbación como observaciones. La variable de respuesta será el arreglo $y$ generado anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vt72l7f5yxwz"
   },
   "outputs": [],
   "source": [
    "# Este arreglo ya lo consideramos anteriormente en la parte P3.4\n",
    "D_p = matriz_perturbaciones.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZxxUxq-rQ6zo"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hCrddD5vyxw4"
   },
   "source": [
    "9. Utilice la clase ``LogisticRegression`` del módulo ``sklearn.linearmodel`` para entrenar un clasificador sobre conjunto de entrenamiento $D_p$. Haga uso de $\\pi_x$ al momento de utilizar el método ``.fit()``. ¿Es posible agregar una medida de complejidad $\\Omega(g)$ con este esquema? argumente al respecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "3a67X9fqyxw5",
    "outputId": "5257ba3e-ba64-4e73-b8a7-2de560fb4a6b"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "import pandas as pd\n",
    "\n",
    "def train_and_test_logreg(D_p, y, vec_pi):\n",
    "    '''\n",
    "    input:\n",
    "    D_p: Conjunto de entrenamiento\n",
    "    y: vector de labels \n",
    "    vec_pi: vector de pesos para D_p\n",
    "\n",
    "    return:\n",
    "    Modelo de regresión logística entrenado\n",
    "    '''\n",
    "\n",
    "    X_train, X_test, y_train, y_test, sw_train, sw_test = train_test_split(D_p,\n",
    "                                                    y,\n",
    "                                                    vec_pi,\n",
    "                                                    shuffle=True,\n",
    "                                                    test_size = 0.2,\n",
    "                                                    stratify = y)\n",
    "\n",
    "    l_model = LogisticRegression()\n",
    "    l_model.fit(X_train, y_train, sample_weight = sw_train)\n",
    "    y_pred = l_model.predict(X_test)\n",
    "\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred) \n",
    "    classes = unique_labels(y_test, y_pred)\n",
    "\n",
    "    plt.figure(figsize = (5,5))\n",
    "\n",
    "    g = sns.heatmap(pd.DataFrame(cm, index = classes, columns = classes),\n",
    "                  annot=True, fmt = 'd', \n",
    "                  cmap=\"Blues\")\n",
    "    g.set_yticklabels(g.get_yticklabels(), rotation = 0)\n",
    "\n",
    "    plt.title('Matriz de Confusión')\n",
    "    plt.xlabel('Label Predecido')\n",
    "    plt.ylabel('Label Real')\n",
    "\n",
    "    return l_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 532
    },
    "colab_type": "code",
    "id": "jXJPT8Lz2Nuc",
    "outputId": "f9504cf6-5a0e-4286-b577-b376f791937c"
   },
   "outputs": [],
   "source": [
    "log_control = train_and_test_logreg(D_p, y, vec_pi_x)\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ElpETAbNyxxB"
   },
   "source": [
    "10. Utilice los coeficientes del clasificador anterior para inferir los super-píxeles de mayor importancia en la clasificación de la imagen de control. Obtenga una visualización y discuta al respecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kBTLpgf9yxxC"
   },
   "outputs": [],
   "source": [
    "def evaluate_coefs(log_coefs, slic, to_save, vgg = False, vgg_image = None):\n",
    "    '''\n",
    "    Funcion que entrega los coeficientes más importantes según criterio de mean(abs) y \n",
    "    entrega la imagen correspondiente a los coeficientes más altos y más bajos\n",
    "    '''\n",
    "    segmento = range(1,len(log_coefs[0])+1)\n",
    "    aux_df = pd.DataFrame({'val_coef':log_coefs[0]} , index = segmento)\n",
    "\n",
    "    high_value_coef = aux_df.loc[aux_df.val_coef > np.mean(abs(aux_df.val_coef))].index\n",
    "    low_value_coef = aux_df.nsmallest(5, 'val_coef').index\n",
    "\n",
    "    fig,ax = plt.subplots(figsize = (12,8))\n",
    "    aux_df.plot(kind = 'bar', ax = ax)\n",
    "    plt.axhline(y=np.mean(abs(aux_df.val_coef)), color='r', linestyle='-')\n",
    "    ax.tick_params(axis = 'x', labelsize = 10)\n",
    "    ax.set_ylabel('Valor_ Coef.')\n",
    "    ax.set_xlabel('Segmento')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(drive_path + to_save + '.pdf', format = 'pdf', dpi = 600)\n",
    "    plt.show()\n",
    "\n",
    "    if vgg:\n",
    "        image_coef = np.array(vgg_image)\n",
    "    else:\n",
    "        image_coef = np.array(im_reboot)\n",
    "\n",
    "    im_best = np.copy(image_coef)\n",
    "    im_worst = np.copy(image_coef)\n",
    "\n",
    "    for j in range(image_coef.shape[0]):\n",
    "        for k in range(image_coef.shape[1]):\n",
    "            n_pix = slic[j,k]\n",
    "            if n_pix not in high_value_coef:\n",
    "                im_best[j,k] = [0, 0, 0]\n",
    "\n",
    "    for j in range(image_coef.shape[0]):\n",
    "        for k in range(image_coef.shape[1]):\n",
    "            n_pix = slic[j,k]\n",
    "            if n_pix not in low_value_coef:\n",
    "                im_worst[j,k] = [0, 0, 0]\n",
    "\n",
    "    print('El promedio de los abs de los coeficientes es de {:.2f}'.format(np.mean(abs(aux_df.val_coef))))\n",
    "\n",
    "    return aux_df, im_best, im_worst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 560
    },
    "colab_type": "code",
    "id": "PgbrDq8M2U9-",
    "outputId": "83be7432-aa30-4531-9678-2115d4a96f60"
   },
   "outputs": [],
   "source": [
    "df_control, image_best_control, image_worst_control = evaluate_coefs(log_control.coef_, segmented_image,\n",
    "                                                                     to_save = 'control_coefs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "colab_type": "code",
    "id": "eAP2J-VH49RR",
    "outputId": "f175db8f-c064-4468-d84d-13052a5e87ee"
   },
   "outputs": [],
   "source": [
    "io.imshow(image_best_control)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "33iKKtueyxxH"
   },
   "source": [
    "La segmentación antes utilizada se hace de *manera espacial*. Es decir, se realiza una clusterización sobre la escala de grises según su posición en la imagen. Del procedimiento recién explicado para implementar LIME reemplace la etapa de segmentación de la imagen por 2 segmentaciones espaciales utilizando 2 modelos de clustering a su elección, para ello:\n",
    "11. Clusterice sobre un conjunto de entrenamiento $X$ con $299^2$ observaciones, es decir, una observación por píxel en la imagen de control escalada. Cada observación de $X$ consta de 3 componentes, donde la primera y segunda son espaciales (posición del píxel en la imagen) y la última es el valor de intensidad asociado al píxel (escala de grises). Utilice los clusters descubiertos para generar super-píxeles.  \n",
    "  \n",
    "  *Hint:* En Scikit-learn el método ``fit_predict`` en algoritmos de clustering puede ser de ayuda para generar super-píxeles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z5FYp0jFYBDK"
   },
   "source": [
    "Se seleccionaron los métodos de kmeans y GaussianMixture para la clusterización, esto debido a la cantidad de datos del problema, estos algoritmos escalan bien con el número de estos.\n",
    "\n",
    "Lo primero a realizar es crear el dataset que se menciona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GO38c6w1aLdh"
   },
   "outputs": [],
   "source": [
    "# Se convierte la imagen a escala de grises\n",
    "gray_im = im_reboot.convert('L')\n",
    "\n",
    "# Se pasa a un array\n",
    "np_gray_im = np.array(gray_im)\n",
    "\n",
    "# Se crea el dataframe con las indicaciones\n",
    "# (posición x, posición y, número en escala de grises)\n",
    "df_X = []\n",
    "for i in range(299):\n",
    "    for j in range(299):\n",
    "        df_X.append([i, j, np_gray_im[i,j]])\n",
    "\n",
    "df_X = np.array(df_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PIzzyLw_YpFz"
   },
   "source": [
    "## K-Means\n",
    "Se importa el modelo KMeans, además de métricas que nos ayudarán en la selección del número de clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XsGswkCW5Y8Q"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_samples, silhouette_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lujj8H2JYvSU"
   },
   "source": [
    "Se crean funciones auxiliares que nos permitirán escoger de mejor forma el número de clusters para kmeans. Se implementa el método del codo además del método de la Silueta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4x-CHq-665w3"
   },
   "outputs": [],
   "source": [
    "# Rango de clusters a buscar\n",
    "range_clusters_SSE = range(5,20)\n",
    "range_clusters = range(5,20)\n",
    "\n",
    "def SSE_AVGS(dataset):\n",
    "    sse_kmeans = []\n",
    "    vec_prom_kmeans=[]\n",
    "\n",
    "    for k in range_clusters_SSE:\n",
    "        kmeans = KMeans(n_clusters=k, random_state=1)\n",
    "        kmeans.fit(dataset)\n",
    "        sse_kmeans.append(kmeans.inertia_)\n",
    "        if k>=2:\n",
    "            silhouette_avg = silhouette_score(dataset,\n",
    "                                              kmeans.fit_predict(dataset) )\n",
    "            vec_prom_kmeans.append(silhouette_avg)\n",
    "    return sse_kmeans, vec_prom_kmeans\n",
    "\n",
    "\n",
    "def FuncionPlot(sse, vec_prom):\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    plt.figure(figsize = (15,10))\n",
    "\n",
    "    ax2.plot(range_clusters_SSE, sse)\n",
    "    ax1.set_xlabel('Número de Clusters')\n",
    "    ax1.set_ylabel('Promedio Score Silueta')\n",
    "    ax1.set_title('Promedio Score Silueta por K Clusters',\n",
    "             fontsize = 20)\n",
    "\n",
    "    ax1.plot(range_clusters, vec_prom)\n",
    "    ax2.set_xlabel('Número de Clusters')\n",
    "    ax2.set_ylabel('Valor SSE')\n",
    "    ax2.set_title('Valor SSE por número de clusters',\n",
    "             fontsize = 20)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RyM3ukIV7IXa"
   },
   "outputs": [],
   "source": [
    "# Demora mucho esto\n",
    "#sse_im, avg_sil_im = SSE_AVGS(df_X)\n",
    "#FuncionPlot(sse_im, avg_sil_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iBCFAeoc7rUS"
   },
   "outputs": [],
   "source": [
    "# clusters_image = range_clusters_SSE[np.argmax(avg_sil_im)]\n",
    "n_clusters_kmeans = 17 # Buen número, sobre ese igual apaña"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LEh6mELBZN5d"
   },
   "source": [
    "Se aplica el modelo Kmeans sobre el conjunto creado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GXqt1EYE79FC"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters = n_clusters_kmeans, random_state = 1).fit(df_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PrCwX2z5ZnAy"
   },
   "source": [
    "Se utilizan los labels obtenidos para etiquetar los datos (pixeles) para así obtener los superpixeles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aU4x2clwKEty"
   },
   "outputs": [],
   "source": [
    "df_X_kmeans = np.c_[df_X, kmeans.labels_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f5eGlh7UJ6Gl"
   },
   "outputs": [],
   "source": [
    "def slic_model(df_X_model, n_centercrop):\n",
    "    slic_model = np.zeros((n_centercrop,n_centercrop))\n",
    "\n",
    "    for i in range(n_centercrop*n_centercrop):\n",
    "        slic_model[df_X_model[i][0]][df_X_model[i][1]] = int(df_X_model[i][3])\n",
    "\n",
    "    slic_model = slic_model.astype(int)\n",
    "    return slic_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "colab_type": "code",
    "id": "mmEDRYA3LHKQ",
    "outputId": "0fbd7364-a7cf-432a-cd16-90d5172fcda7"
   },
   "outputs": [],
   "source": [
    "slic_kmeans = slic_model(df_X_kmeans, n_centercrop)\n",
    "io.imshow(mark_boundaries(gray_im, slic_kmeans))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z1bS3kxBaYoQ"
   },
   "source": [
    "## Gaussian Mixture\n",
    "\n",
    "se importa el modelo y, a priori, un número de componentes igual a 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fjE_KS2m4cA_"
   },
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "GM = GaussianMixture(n_components= 17).fit(df_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eMrRh9X2av2E"
   },
   "source": [
    "Se crea el dataset y las etiquetas de cada pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LVkvoi1R4uj2"
   },
   "outputs": [],
   "source": [
    "df_X_GM = np.c_[df_X, GM.predict(df_X)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HQYuEvap4x2l"
   },
   "outputs": [],
   "source": [
    "slic_GM = slic_model(df_X_GM, n_centercrop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "colab_type": "code",
    "id": "DGh4c6be43Ul",
    "outputId": "134cb2a7-7d13-44b0-b759-e092007bbae1"
   },
   "outputs": [],
   "source": [
    "io.imshow(mark_boundaries(gray_im, slic_GM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "colab_type": "code",
    "id": "S3Ys3vFJVzIB",
    "outputId": "a71d0f4d-7fea-4909-ff47-f9dd297ba8c5"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize = (8,4))\n",
    "axs[0].imshow(mark_boundaries(gray_im, slic_kmeans))\n",
    "axs[0].set_title('Seg. Kmeans')\n",
    "axs[0].set_ylabel('Alto')\n",
    "axs[0].set_xlabel('Ancho')\n",
    "\n",
    "axs[1].imshow(mark_boundaries(gray_im, slic_GM))\n",
    "axs[1].set_title('Seg. G.M.')\n",
    "axs[1].set_xlabel('Ancho')\n",
    "plt.tight_layout()\n",
    "plt.savefig(drive_path + 'slic_segmentacion.pdf', format = 'pdf', dpi = 600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PkWeOYHSyxxN"
   },
   "source": [
    "\n",
    "  12. Aplique el esquema LIME desarrollado anteriormente sobre sus super-píxeles. Interprete los resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y9OL6450bg4I"
   },
   "source": [
    "## Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PZAWp1zdyxxO"
   },
   "outputs": [],
   "source": [
    "# Creamos la matriz de perturbaciones \n",
    "matriz_perturbaciones_kmeans = bernoulli.rvs(p,size = n_clusters_kmeans * n_perturbaciones, random_state = 10)\n",
    "# Le damos la forma de matriz, donde cada columna representa un vector de \n",
    "# perturbaciones según el número de superpixeles de la imagen\n",
    "matriz_perturbaciones_kmeans = matriz_perturbaciones_kmeans.reshape((n_clusters_kmeans, n_perturbaciones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hHoiN48Tb2zU"
   },
   "outputs": [],
   "source": [
    "vec_images_kmeans = Generador_Pert_Images(image_path, n_perturbaciones,\n",
    "                                          matriz_perturbaciones_kmeans,\n",
    "                                          slic_kmeans, n_centercrop,\n",
    "                                          f_half_image_transformer,\n",
    "                                          s_half_image_transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 346
    },
    "colab_type": "code",
    "id": "Ok_DPRNWcltG",
    "outputId": "707951ba-4442-47aa-94d9-f53b47d4cfae"
   },
   "outputs": [],
   "source": [
    "# Visualizamos lo obtenido\n",
    "plot_multiple_images(vec_images_kmeans[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z64YjpddcvHm"
   },
   "outputs": [],
   "source": [
    "y_kmeans = create_y_vector(label_predict[0][0][1], model_inception, vec_images_kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "YPODA_8OjriS",
    "outputId": "58bce713-fa29-4b10-bb55-c851be244524"
   },
   "outputs": [],
   "source": [
    "# La cantidad de labels bien catalogados es de\n",
    "pd.Series(y_kmeans).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kaggvwm4fW8Y"
   },
   "outputs": [],
   "source": [
    "vec_pi_kmeans = create_pi_vector(n_clusters_kmeans, matriz_perturbaciones_kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fYYgwafQgcx3"
   },
   "outputs": [],
   "source": [
    "D_p_kmeans = matriz_perturbaciones_kmeans.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 532
    },
    "colab_type": "code",
    "id": "g9rkk-2xglOJ",
    "outputId": "6d36c631-22dc-4c3a-c831-1371d0b8caef"
   },
   "outputs": [],
   "source": [
    "log_kmeans = train_and_test_logreg(D_p_kmeans, y_kmeans, vec_pi_kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 560
    },
    "colab_type": "code",
    "id": "DXu3-JmCg1qh",
    "outputId": "128bb52a-360d-45e1-89b5-c344de082878"
   },
   "outputs": [],
   "source": [
    "df_kmeans, seg_kmeans_image_best, seg_kmeans_image_worst = evaluate_coefs(log_kmeans.coef_, slic_kmeans,\n",
    "                                                                          to_save = 'coef_kmeans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "colab_type": "code",
    "id": "X3zbdJM05O0_",
    "outputId": "ccebf7b0-9842-40e0-cb2d-5b24fed01b94"
   },
   "outputs": [],
   "source": [
    "io.imshow(seg_kmeans_image_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WoyQk4IokLZX"
   },
   "source": [
    "## GM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e9zp_d1HkaLC"
   },
   "outputs": [],
   "source": [
    "n_clusters_GM = len(np.unique(slic_GM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nfOuwFHSkNA1"
   },
   "outputs": [],
   "source": [
    "# Creamos la matriz de perturbaciones \n",
    "matriz_perturbaciones_GM = bernoulli.rvs(p,size = n_clusters_GM * n_perturbaciones)\n",
    "# Le damos la forma de matriz, donde cada columna representa un vector de \n",
    "# perturbaciones según el número de superpixeles de la imagen\n",
    "matriz_perturbaciones_GM = matriz_perturbaciones_GM.reshape((n_clusters_GM, n_perturbaciones))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rfKKpn42k42M"
   },
   "outputs": [],
   "source": [
    "vec_images_GM = Generador_Pert_Images(image_path, n_perturbaciones,\n",
    "                                          matriz_perturbaciones_GM,\n",
    "                                          slic_GM, n_centercrop,\n",
    "                                      f_half_image_transformer,\n",
    "                                          s_half_image_transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 346
    },
    "colab_type": "code",
    "id": "m0MGvHPCk8Su",
    "outputId": "6bb34665-9fe3-4f85-9587-d0b3c2b6449c"
   },
   "outputs": [],
   "source": [
    "plot_multiple_images(vec_images_GM[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "50OI1TKBlACn"
   },
   "outputs": [],
   "source": [
    "y_GM = create_y_vector(label_predict[0][0][1], model_inception, vec_images_GM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "1mLOPsYPlAAo",
    "outputId": "d118b53f-52fe-4158-df2e-505a5bd07cba"
   },
   "outputs": [],
   "source": [
    "# La cantidad de labels bien catalogados es de\n",
    "pd.Series(y_GM).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Oz9qPumlk_-Q"
   },
   "outputs": [],
   "source": [
    "vec_pi_GM = create_pi_vector(n_clusters_GM, matriz_perturbaciones_GM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E84zwaBGk_4y"
   },
   "outputs": [],
   "source": [
    "D_p_GM = matriz_perturbaciones_GM.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 532
    },
    "colab_type": "code",
    "id": "4FooPW3ak_2W",
    "outputId": "b9e9754e-01bd-4676-9673-a6a80f649997"
   },
   "outputs": [],
   "source": [
    "log_GM = train_and_test_logreg(D_p_GM, y_GM, vec_pi_GM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 560
    },
    "colab_type": "code",
    "id": "Ef_0uvuCk_w8",
    "outputId": "5fb4551d-c10e-4e06-ed0e-b0ea91418f1c"
   },
   "outputs": [],
   "source": [
    "df_GM, seg_GM_image_best, seg_GM_image_worst = evaluate_coefs(log_GM.coef_, slic_GM,\n",
    "                                                              to_save = 'coefs_GM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mxDV7RQXgPCq"
   },
   "source": [
    "## Comparación KMeans, GM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "colab_type": "code",
    "id": "2rifGDw7lYsW",
    "outputId": "4ad81d99-2381-48d9-fef1-93d937bacdfc"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, ncols=2, figsize = (8,8))\n",
    "axs[0,0].imshow(im_reboot)\n",
    "axs[0,0].set_title('Imagen Original')\n",
    "axs[0,0].set_ylabel('Alto')\n",
    "\n",
    "#axs[0,1].imshow(mark_boundaries(image_coef_control, segmented_image))\n",
    "axs[0,1].imshow(image_best_control)\n",
    "axs[0,1].set_title('Imp. Slic')\n",
    "\n",
    "#axs[1,0].imshow(mark_boundaries(seg_kmeans_image, slic_kmeans))\n",
    "axs[1,0].imshow(seg_kmeans_image_best)\n",
    "axs[1,0].set_title('Imp. Kmeans')\n",
    "axs[1,0].set_xlabel('Ancho')\n",
    "axs[1,0].set_ylabel('Alto')\n",
    "\n",
    "#axs[1,1].imshow(mark_boundaries(seg_GM_image, slic_GM))\n",
    "axs[1,1].imshow(seg_GM_image_best)\n",
    "axs[1,1].set_title('Imp. GM')\n",
    "axs[1,1].set_xlabel('Ancho')\n",
    "plt.tight_layout()\n",
    "plt.savefig(drive_path + 'importantes_general.pdf', format = 'pdf', dpi = 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ZufPT6OGzqkH",
    "outputId": "7054c73d-0806-44e1-98e6-4a20d5ea9f5b"
   },
   "outputs": [],
   "source": [
    "df_control.loc[df_control.val_coef >np.mean(abs(df_control.val_coef))].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Y8Vb2xvhzrDv",
    "outputId": "b637bb98-d316-4b80-b5e6-1aa18f67e436"
   },
   "outputs": [],
   "source": [
    "df_GM.loc[df_GM.val_coef >np.mean(abs(df_GM.val_coef))].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "mNAoYwyszrfE",
    "outputId": "c1af9109-7bc7-4e51-e597-a05da8a57df0"
   },
   "outputs": [],
   "source": [
    "df_kmeans.loc[df_kmeans.val_coef >np.mean(abs(df_kmeans.val_coef))].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q3gOCYOIla1M"
   },
   "source": [
    "# Aplicación LIME sobre VGG16DWSep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tKS8VA16yxxU"
   },
   "source": [
    "*Finalmente* aplique un esquema LIME sobre una predicción de la red ``VGG16DWSep`` implementada en la parte 2 de la tarea. Discuta sus resultados y observaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hPetTwPCoZBp"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pq2F-lujo1cI"
   },
   "outputs": [],
   "source": [
    "\n",
    "class DWSepConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, padding, bias=True):\n",
    "        super().__init__()\n",
    "        self.depthwise = nn.Conv2d(in_channels, in_channels, kernel_size=kernel_size, \n",
    "                                   stride=1,groups=in_channels, padding=padding, bias=bias)\n",
    "        self.pointwise = nn.Conv2d(in_channels, out_channels, kernel_size=1,\n",
    "                                   stride=1, bias=bias)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.depthwise(x.float())\n",
    "        x = F.relu(self.pointwise(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IEH8XTw9oTv5"
   },
   "outputs": [],
   "source": [
    "class VGG16DWSep(nn.Module):\n",
    "    \"\"\"Red neuronal profunda VGG16 con separación Depthwise \n",
    "    descrita en la tabla 1 del enunciado\"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"Se hereda init y se definen todas las capas que participaran\"\"\" \n",
    "        super().__init__()\n",
    "        self.dw1 = DWSepConv2d(64, 128, 3, 1)\n",
    "        self.dw2 = DWSepConv2d(128,128, 3, 1)\n",
    "        self.dw3 = DWSepConv2d(128,256, 3, 1)\n",
    "        self.dw4 = DWSepConv2d(256,256, 3, 1)\n",
    "        self.dw5 = DWSepConv2d(256,256, 3, 1)\n",
    "        self.dw6 = DWSepConv2d(256,512, 3, 1)\n",
    "        self.dw7 = DWSepConv2d(512,512, 3, 1)\n",
    "        self.dw8 = DWSepConv2d(512,512, 3, 1)\n",
    "        self.conv1 = nn.Conv2d(3, 64, 3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64,64, 3, stride=1, padding=1)\n",
    "        self.max1 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.max2 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.max3 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.max4 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.bat1= nn.BatchNorm2d(256)\n",
    "        self.bat2= nn.BatchNorm2d(256)\n",
    "        self.bat3= nn.BatchNorm2d(512)\n",
    "        self.bat4= nn.BatchNorm2d(512)\n",
    "        self.lin1= nn.Linear(100352, 1024)\n",
    "        self.lin2= nn.Linear(1024,512)\n",
    "        self.lin3= nn.Linear(512,2)\n",
    "        self.drop1=nn.Dropout(p=0.7)\n",
    "        self.drop2=nn.Dropout(p=0.5)\n",
    "        self.flat= nn.Flatten()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"Se define el proceso en el orden que indica la tabla, usando la\n",
    "        funcion de activacion ReLU donde corresponda\"\"\"\n",
    "        x = x.view(-1,3,224,224)\n",
    "        x = F.relu(self.conv1(x.float()))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.max1(x)\n",
    "        x = self.dw1(x)\n",
    "        x = self.dw2(x)\n",
    "        x = self.max2(x)\n",
    "        x = self.dw3(x)\n",
    "        x = F.relu(self.bat1(x))\n",
    "        x = self.dw4(x)\n",
    "        x = F.relu(self.bat2(x))\n",
    "        x = self.dw5(x)\n",
    "        x = self.max3(x)\n",
    "        x = self.dw6(x)\n",
    "        x = F.relu(self.bat3(x))\n",
    "        x = self.dw7(x)\n",
    "        x = F.relu(self.bat4(x))\n",
    "        x = self.dw8(x)\n",
    "        x = self.max4(x)\n",
    "        x = self.flat(x)\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = self.drop1(x)\n",
    "        x = F.relu(self.lin2(x))\n",
    "        x = self.drop2(x)\n",
    "        x = F.relu(self.lin3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lu_LSM0MlgLF"
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model_VGG16DWSep = VGG16DWSep()\n",
    "model_VGG16DWSep.load_state_dict(torch.load(drive_path + 'modelo.h5'))\n",
    "model_VGG16DWSep.to(device)\n",
    "model_VGG16DWSep.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aNnHFJ9AtUcN"
   },
   "outputs": [],
   "source": [
    "n_centercrop_vgg = 224\n",
    "image_transformer_vgg =  torch_transforms.Compose([\n",
    "                                              torch_transforms.Resize([224, 224]),\n",
    "                                              torch_transforms.CenterCrop(n_centercrop_vgg),\n",
    "                                              torch_transforms.ToTensor(),\n",
    "                                              torch_transforms.Normalize(mean_transform, std_transform)\n",
    "                                              ])\n",
    "\n",
    "f_half_image_transformer_vgg =  torch_transforms.Compose([\n",
    "                                              torch_transforms.Resize([224, 224]),\n",
    "                                              torch_transforms.CenterCrop(n_centercrop_vgg)\n",
    "                                              ])\n",
    "\n",
    "s_half_image_transformer_vgg =  torch_transforms.Compose([\n",
    "                                              torch_transforms.ToTensor(),\n",
    "                                              torch_transforms.Normalize(mean_transform, std_transform)\n",
    "                                              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6aXamBwX57yA"
   },
   "outputs": [],
   "source": [
    "def loader(input):\n",
    "    '''Funcion que carga la imagen, si es de 1 canal la pasa a 3 canales '''\n",
    "    image = Image.open(input)\n",
    "    img = image.split()\n",
    "    if len(img) == 1:\n",
    "        return Image.merge('RGB', (img[0], img[0], img[0]))\n",
    "    else:\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PncpGgghl72S"
   },
   "outputs": [],
   "source": [
    "im_nem =loader(drive_path + 'neumonia_4.jpeg')\n",
    "im_nem_transformed = image_transformer_vgg(im_nem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "Zexjq1UssmBU",
    "outputId": "3d0fc54e-e908-4167-d439-a73c972ce8d7"
   },
   "outputs": [],
   "source": [
    "plot_multiple_images_control(im_nem,im_nem_transformed.cpu())\n",
    "plt.savefig(drive_path + 'imagen_vgg_trans.pdf', format = 'pdf', dpi = 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KhyyAThGsqep"
   },
   "outputs": [],
   "source": [
    "im_nem_transformed = im_nem_transformed.to(device)\n",
    "pred_image_v = model_VGG16DWSep(im_nem_transformed)\n",
    "aux_pred_v = np.expand_dims(pred_image_v.cpu().detach().numpy(), axis=0)\n",
    "aux_pred_v\n",
    "label_vgg_predict = np.argmax(aux_pred_v[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A-V1PUmmu-NO"
   },
   "outputs": [],
   "source": [
    "im_reboot_vgg = im_nem_transformed.cpu()*torch.tensor(std_transform).view(3,1,1)\n",
    "im_reboot_vgg = im_reboot_vgg + torch.tensor(mean_transform).view(3,1,1)\n",
    "\n",
    "im_reboot_vgg = torch_transforms.ToPILImage(mode = 'RGB')(im_reboot_vgg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KiZPPPGGvKqA"
   },
   "outputs": [],
   "source": [
    "slic_vgg =  slic(im_reboot_vgg, n_segments = n_segments) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "colab_type": "code",
    "id": "l5uZY83JvOoy",
    "outputId": "45191e1f-8bf6-4c41-a631-a91681fc0a15"
   },
   "outputs": [],
   "source": [
    "io.imshow(mark_boundaries(im_reboot_vgg, slic_vgg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ygzS0kyKvkzv"
   },
   "outputs": [],
   "source": [
    "n_superpixeles_vgg = len(np.unique(slic_vgg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5SgcQ82VvT7F"
   },
   "outputs": [],
   "source": [
    "# Creamos la matriz de perturbaciones \n",
    "matriz_perturbaciones_vgg = bernoulli.rvs(p,size = n_superpixeles_vgg * n_perturbaciones)\n",
    "# Le damos la forma de matriz, donde cada columna representa un vector de \n",
    "# perturbaciones según el número de superpixeles de la imagen\n",
    "matriz_perturbaciones_vgg = matriz_perturbaciones_vgg.reshape((n_superpixeles_vgg, n_perturbaciones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vjptr5ZKvT24"
   },
   "outputs": [],
   "source": [
    "vec_images_vgg = Generador_Pert_Images(drive_path + 'neumonia_4.jpeg', n_perturbaciones,\n",
    "                                          matriz_perturbaciones_vgg,\n",
    "                                          slic_vgg, n_centercrop_vgg,\n",
    "                                       f_half_image_transformer_vgg,\n",
    "                                       s_half_image_transformer_vgg, vgg = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 591
    },
    "colab_type": "code",
    "id": "ETC7BHneqLJd",
    "outputId": "9e0a4853-f7e8-4497-e7e0-0eafbec66427"
   },
   "outputs": [],
   "source": [
    "# Visualizamos la imagen segmentada y una perturbacion cualquiera\n",
    "plot_slic_image_vec(im_reboot_vgg, slic_vgg, vec_images_vgg[0])\n",
    "plt.savefig(drive_path + 'vgg_pert_seg.pdf', format = 'pdf', dpi = 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hkJhWxNDvSKK"
   },
   "outputs": [],
   "source": [
    "y_vgg = create_y_vector(label_vgg_predict, model_VGG16DWSep, vec_images_vgg,\n",
    "                        vgg = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "BevUNghgvSEB",
    "outputId": "1348ca1f-63da-4c62-b386-29f60814851d"
   },
   "outputs": [],
   "source": [
    "pd.Series(y_vgg).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7AzT2mVivSAZ"
   },
   "outputs": [],
   "source": [
    "vec_pi_vgg = create_pi_vector(n_superpixeles_vgg, matriz_perturbaciones_vgg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LUtWxUxV0_k1"
   },
   "outputs": [],
   "source": [
    "D_p_vgg = matriz_perturbaciones_vgg.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 532
    },
    "colab_type": "code",
    "id": "-XAOHVcCvR7b",
    "outputId": "a25fb15d-f0be-4d75-bb64-d69a5161bafe"
   },
   "outputs": [],
   "source": [
    "log_vgg= train_and_test_logreg(D_p_vgg, y_vgg, vec_pi_vgg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 560
    },
    "colab_type": "code",
    "id": "uqJl1Ht4vRsQ",
    "outputId": "6f8844eb-4a18-4dbf-c1ed-435636135121"
   },
   "outputs": [],
   "source": [
    "df_vgg, seg_vgg_image_best, seg_vgg_image_worst = evaluate_coefs(log_vgg.coef_, slic_vgg, to_save = 'coef_vgg',\n",
    "                                       vgg = True, vgg_image = im_reboot_vgg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "colab_type": "code",
    "id": "OPWSPMJJuh2p",
    "outputId": "b0d46636-e22a-4166-aad8-e151498aa40a"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2, figsize = (8,8))\n",
    "axs[0].imshow(im_reboot_vgg)\n",
    "axs[0].set_title('Imagen Original')\n",
    "axs[0].set_ylabel('Alto')\n",
    "\n",
    "#axs[0,1].imshow(mark_boundaries(image_coef_control, segmented_image))\n",
    "axs[1].imshow(seg_vgg_image_best)\n",
    "axs[1].set_title('Imp. Slic')\n",
    "\n",
    "plt.savefig(drive_path + 'vgg_importantes.pdf', format = 'pdf', dpi = 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ra1aX820z4Zl",
    "outputId": "a3c34b56-f739-4ec0-9d8a-0b57677bb477"
   },
   "outputs": [],
   "source": [
    "df_vgg.loc[df_vgg.val_coef >np.mean(abs(df_vgg.val_coef))].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qqeALaK2yxxV"
   },
   "source": [
    "**(Bonus)** Se puede hacer segmentación en el espacio de colores, en este caso, el conjunto a segmentar consiste en una transformación de la imagen de control escalada en un arreglo de dimensión (ancho$\\cdot$largo)$\\times 3$ (en el caso de ``inception_v3``, la dimesión sería $299^2\\times 3$). Sobre este nuevo arreglo implemente un algoritmo de clustering y genere super-píxeles. Aplique un esquema LIME con una familia $G$ no basada en modelos lineales y compare con la misma familia sobre un método de segmentación espacial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AFpfI-gTyxxW"
   },
   "outputs": [],
   "source": [
    "# Se pasa a un array\n",
    "im_reboot_array = np.array(im_reboot)\n",
    "\n",
    "# Se crea el dataframe con las indicaciones\n",
    "# (posición x, posición y, número en escala de grises)\n",
    "df_X_color = []\n",
    "for i in range(299):\n",
    "    for j in range(299):\n",
    "        df_X_color.append([i, j, *im_reboot_array[i,j]])\n",
    "\n",
    "df_X_color = np.array(df_X_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EEpBdFASliY7"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans_color = KMeans(n_clusters = 14, random_state = 1).fit(df_X_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uCSzQdcZl_3e"
   },
   "outputs": [],
   "source": [
    "df_X_color_kmeans = np.c_[df_X_color, kmeans_color.labels_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Yem_CSZmUwg"
   },
   "outputs": [],
   "source": [
    "def slic_model_color(df_X_model, n_centercrop):\n",
    "    slic_model = np.zeros((n_centercrop,n_centercrop))\n",
    "\n",
    "    for i in range(n_centercrop*n_centercrop):\n",
    "        slic_model[df_X_model[i][0]][df_X_model[i][1]] = int(df_X_model[i][5])\n",
    "\n",
    "    slic_model = slic_model.astype(int)\n",
    "    return slic_model\n",
    "\n",
    "slic_kmeans_color = slic_model_color(df_X_color_kmeans, 299)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "colab_type": "code",
    "id": "8_Ar-y2QmIYW",
    "outputId": "d64e5a1c-00bc-4b88-f888-3534f5640333"
   },
   "outputs": [],
   "source": [
    "io.imshow(mark_boundaries(im_reboot, slic_kmeans_color))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JXi84H40muwi"
   },
   "outputs": [],
   "source": [
    "# Creamos la matriz de perturbaciones \n",
    "matriz_perturbaciones_kmeans_color = bernoulli.rvs(p,size = 15 * n_perturbaciones, random_state = 10)\n",
    "# Le damos la forma de matriz, donde cada columna representa un vector de \n",
    "# perturbaciones según el número de superpixeles de la imagen\n",
    "matriz_perturbaciones_kmeans_color = matriz_perturbaciones_kmeans_color.reshape((15, n_perturbaciones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dtTKlNh2m7bS"
   },
   "outputs": [],
   "source": [
    "vec_images_color_kmeans = Generador_Pert_Images(drive_path + 'tiger_2.jpg', n_perturbaciones,\n",
    "                                          matriz_perturbaciones_kmeans_color,\n",
    "                                          slic_kmeans_color, 299,\n",
    "                                       f_half_image_transformer,\n",
    "                                       s_half_image_transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 591
    },
    "colab_type": "code",
    "id": "xBfUff_BnOeq",
    "outputId": "85702e89-d186-4fba-f487-fc61610b6fce"
   },
   "outputs": [],
   "source": [
    "plot_slic_image_vec(im_reboot, slic_kmeans_color, vec_images_color_kmeans[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tHBfwIBOnaAQ"
   },
   "outputs": [],
   "source": [
    "y_color_kmeans = create_y_vector(label_predict[0][0][1], model_inception, vec_images_color_kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "OEVHbf3rntHN",
    "outputId": "a502f50a-9be6-49c2-b59b-beda79342d0b"
   },
   "outputs": [],
   "source": [
    "# La cantidad de labels bien catalogados es de\n",
    "pd.Series(y_color_kmeans).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bfnorydbnuzJ"
   },
   "outputs": [],
   "source": [
    "vec_pi_color_kmeans = create_pi_vector(15, matriz_perturbaciones_kmeans_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bR78h4X0nzuS"
   },
   "outputs": [],
   "source": [
    "D_p_kmeans_color = matriz_perturbaciones_kmeans_color.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6X1ZgFDgoHE3"
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 550
    },
    "colab_type": "code",
    "id": "6xCCDddIphMB",
    "outputId": "f35e42f1-44b2-40ca-f907-8ae9d63f8d03"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, sw_train, sw_test = train_test_split(D_p_kmeans_color,\n",
    "                                                    y_color_kmeans,\n",
    "                                                    vec_pi_color_kmeans,\n",
    "                                                    shuffle=True,\n",
    "                                                    test_size = 0.2,\n",
    "                                                    stratify = y_color_kmeans)\n",
    "\n",
    "xgb_classifier = xgb.XGBClassifier()\n",
    "xgb_classifier.fit(X_train, y_train, sample_weight = sw_train)\n",
    "y_pred = xgb_classifier.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred) \n",
    "classes = unique_labels(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize = (5,5))\n",
    "\n",
    "g = sns.heatmap(pd.DataFrame(cm, index = classes, columns = classes),\n",
    "                annot=True, fmt = 'd', \n",
    "                cmap=\"Blues\")\n",
    "g.set_yticklabels(g.get_yticklabels(), rotation = 0)\n",
    "\n",
    "plt.title('Matriz de Confusión')\n",
    "plt.xlabel('Label Predecido')\n",
    "plt.ylabel('Label Real')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 342
    },
    "colab_type": "code",
    "id": "NzEkPNjgqcws",
    "outputId": "23427a6a-58a7-4375-eb94-aece222ceb13"
   },
   "outputs": [],
   "source": [
    "df_xgb = pd.DataFrame({'gain' :xgb_classifier.feature_importances_,\n",
    "              'coef': range(1,16)}).set_index('coef')\n",
    "\n",
    "df_xgb.sort_values(by = 'gain').plot(kind = 'barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-OBH1_FXrM3c"
   },
   "outputs": [],
   "source": [
    "high_xgb = df_xgb.nlargest(4, 'gain').index\n",
    "image_xgb = np.array(f_half_image_transformer(Image.open(image_path)))\n",
    "for j in range(image_xgb.shape[0]):\n",
    "    for k in range(image_xgb.shape[1]):\n",
    "        n_pix = slic_kmeans_color[j,k]\n",
    "        if n_pix not in high_xgb:\n",
    "            image_xgb[j,k] = [0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "colab_type": "code",
    "id": "FCGtbKd3sTBM",
    "outputId": "25698d31-6d68-4451-ad73-4050a6e4290a"
   },
   "outputs": [],
   "source": [
    "io.imshow(image_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "colab_type": "code",
    "id": "uu7EG64Ws0gy",
    "outputId": "f108e6a4-6285-4d8b-a917-f25394edf0ec"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2, figsize = (8,8))\n",
    "axs[0].imshow(mark_boundaries(im_reboot, slic_kmeans_color))\n",
    "axs[0].set_title('Seg. Kmeans Color')\n",
    "axs[0].set_ylabel('Alto')\n",
    "\n",
    "#axs[0,1].imshow(mark_boundaries(image_coef_control, segmented_image))\n",
    "axs[1].imshow(image_xgb)\n",
    "axs[1].set_title('Imp. Kmeans Color')\n",
    "\n",
    "plt.savefig(drive_path + 'color_kmeans.pdf', format = 'pdf', dpi = 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FJUsm_VXtBw-"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "dv6n5-MbyxwA"
   ],
   "name": "tarea2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 497.08333400000004,
   "position": {
    "height": "259.317px",
    "left": "1053.77px",
    "right": "20px",
    "top": "154px",
    "width": "498.7px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
